{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f939d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checking folder: vector_paragraphs ===\n",
      "[OK] roger_federer -> npy=4370, jsonl=4370\n",
      "[OK] mohamed_salah -> npy=2666, jsonl=2666\n",
      "[OK] bob_bland -> npy=3107, jsonl=3107\n",
      "[OK] emmanuel_macron -> npy=3863, jsonl=3863\n",
      "[OK] andres_manuel_lopez -> npy=3244, jsonl=3244\n",
      "[OK] maxine_waters -> npy=5047, jsonl=5047\n",
      "[OK] guillermo_del_toro -> npy=2965, jsonl=2965\n",
      "[OK] john_legend -> npy=5281, jsonl=5281\n",
      "[OK] chip_gaines -> npy=3115, jsonl=3115\n",
      "[OK] ann_mckee -> npy=2466, jsonl=2466\n",
      "[OK] mahershala_ali -> npy=4835, jsonl=4835\n",
      "[OK] jesmyn_ward -> npy=3750, jsonl=3750\n",
      "[OK] julian_assange -> npy=4010, jsonl=4010\n",
      "[OK] prince_harry -> npy=6205, jsonl=6205\n",
      "[OK] jordan_peele -> npy=5471, jsonl=5471\n",
      "[OK] judy_chicago -> npy=4164, jsonl=4164\n",
      "[OK] glenn_close -> npy=2644, jsonl=2644\n",
      "[OK] moon_jae_in -> npy=4308, jsonl=4308\n",
      "[OK] sean_hannity -> npy=5331, jsonl=5331\n",
      "[OK] christine_blasey_ford -> npy=5055, jsonl=5055\n",
      "[OK] jennifer_hyman -> npy=3197, jsonl=3197\n",
      "[OK] mohamed_bin_zayed -> npy=5971, jsonl=5971\n",
      "[OK] carl_june -> npy=2310, jsonl=2310\n",
      "[OK] gavin_grimm -> npy=2417, jsonl=2417\n",
      "[OK] jeff_bezos -> npy=4933, jsonl=4933\n",
      "[OK] margaret_atwood -> npy=5393, jsonl=5393\n",
      "[OK] glenda_gray -> npy=2277, jsonl=2277\n",
      "[OK] emilia_clarke -> npy=3856, jsonl=3856\n",
      "[OK] david_hogg -> npy=2043, jsonl=2043\n",
      "[OK] ruth_davidson -> npy=3696, jsonl=3696\n",
      "[OK] jean_liu -> npy=6100, jsonl=6100\n",
      "[OK] jennifer_lopez -> npy=3788, jsonl=3788\n",
      "[OK] maria_ressa -> npy=3332, jsonl=3332\n",
      "[OK] mohammed_bin_salman -> npy=5596, jsonl=5596\n",
      "[OK] margot_robbie -> npy=2375, jsonl=2375\n",
      "[OK] michelle_obama -> npy=3266, jsonl=3266\n",
      "[OK] elizabeth_diller -> npy=5453, jsonl=5453\n",
      "[OK] bernard_tyson -> npy=2711, jsonl=2711\n",
      "[OK] ryan_murphy -> npy=10452, jsonl=10452\n",
      "[OK] chloe_kim -> npy=5800, jsonl=5800\n",
      "[OK] robert_mueller -> npy=2974, jsonl=2974\n",
      "[OK] sandra_day_oconnor -> npy=3663, jsonl=3663\n",
      "[OK] juan_guaido -> npy=2652, jsonl=2652\n",
      "[OK] indya_moore -> npy=4346, jsonl=4346\n",
      "[OK] kerry_james_marshall -> npy=3629, jsonl=3629\n",
      "[OK] nancy_pelosi -> npy=2392, jsonl=2392\n",
      "[OK] samantha_bee -> npy=2264, jsonl=2264\n",
      "[OK] jr_artist -> npy=3592, jsonl=3592\n",
      "[OK] elizabeth_warren -> npy=8474, jsonl=8474\n",
      "[OK] jeff_sessions -> npy=8686, jsonl=8686\n",
      "[OK] ryan_reynolds -> npy=8466, jsonl=8466\n",
      "[OK] chance_the_rapper -> npy=2790, jsonl=2790\n",
      "[OK] he_jiankui -> npy=2504, jsonl=2504\n",
      "[OK] donald_trump -> npy=26516, jsonl=26516\n",
      "[OK] colin_kaepernick -> npy=3326, jsonl=3326\n",
      "[OK] imran_khan -> npy=4470, jsonl=4470\n",
      "[OK] mirian_g -> npy=4094, jsonl=4094\n",
      "[OK] justin_trudeau -> npy=4983, jsonl=4983\n",
      "[OK] bob_ferguson -> npy=3922, jsonl=3922\n",
      "[OK] ryan_coogler -> npy=7441, jsonl=7441\n",
      "[OK] jason_blum -> npy=5276, jsonl=5276\n",
      "[OK] sadiq_khan -> npy=4420, jsonl=4420\n",
      "[OK] barry_jenkins -> npy=5999, jsonl=5999\n",
      "[OK] alex_morgan -> npy=5829, jsonl=5829\n",
      "[OK] john_lewis -> npy=4675, jsonl=4675\n",
      "[OK] jerome_powell -> npy=2436, jsonl=2436\n",
      "[OK] emily_comer -> npy=3693, jsonl=3693\n",
      "[OK] alicia_keys -> npy=2544, jsonl=2544\n",
      "[OK] emma_stone -> npy=5044, jsonl=5044\n",
      "[OK] janet_mock -> npy=3141, jsonl=3141\n",
      "[OK] emma_gonzalez -> npy=5232, jsonl=5232\n",
      "[OK] juan_manuel_santos -> npy=5050, jsonl=5050\n",
      "[OK] kim_jong_un -> npy=6121, jsonl=6121\n",
      "[OK] jay_oneal -> npy=3077, jsonl=3077\n",
      "[OK] jimmy_kimmel -> npy=3650, jsonl=3650\n",
      "[OK] christopher_wylie -> npy=6043, jsonl=6043\n",
      "[OK] jian_wei_pan -> npy=3397, jsonl=3397\n",
      "[OK] barbara_rae_venter -> npy=2635, jsonl=2635\n",
      "[OK] pat_mcgrath -> npy=3366, jsonl=3366\n",
      "[OK] jane_goodall -> npy=5112, jsonl=5112\n",
      "[OK] ivanka_trump -> npy=8119, jsonl=8119\n",
      "[OK] pope_francis -> npy=4646, jsonl=4646\n",
      "[OK] jeanne_gang -> npy=4581, jsonl=4581\n",
      "[OK] barbara_lynch -> npy=3256, jsonl=3256\n",
      "[OK] mauricio_macri -> npy=2261, jsonl=2261\n",
      "[OK] chuck_schumer -> npy=2254, jsonl=2254\n",
      "[OK] cindy_holland -> npy=2431, jsonl=2431\n",
      "[OK] millie_bobby_brown -> npy=2341, jsonl=2341\n",
      "[OK] jose_andres -> npy=2786, jsonl=2786\n",
      "[OK] ashley_graham -> npy=5068, jsonl=5068\n",
      "[OK] benjamin_netanyahu -> npy=3247, jsonl=3247\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# 검사할 상위 폴더들\n",
    "gpu_dirs = [\n",
    "    \"vector_paragraphs\"\n",
    "]\n",
    "\n",
    "def count_jsonl(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "def check_folder(folder):\n",
    "    print(f\"\\n=== Checking folder: {folder} ===\")\n",
    "\n",
    "    files = os.listdir(folder)\n",
    "\n",
    "    # basename 목록 생성 (예: alex_morgan)\n",
    "    basenames = set()\n",
    "    for f in files:\n",
    "        if f.endswith(\"_embeddings.npy\"):\n",
    "            basenames.add(f.replace(\"_embeddings.npy\", \"\"))\n",
    "        if f.endswith(\"_metadata.jsonl\"):\n",
    "            basenames.add(f.replace(\"_metadata.jsonl\", \"\"))\n",
    "\n",
    "    for name in basenames:\n",
    "        npy_path = os.path.join(folder, f\"{name}_embeddings.npy\")\n",
    "        jsonl_path = os.path.join(folder, f\"{name}_metadata.jsonl\")\n",
    "\n",
    "        if not os.path.exists(npy_path) or not os.path.exists(jsonl_path):\n",
    "            print(f\"[MISSING] {name}: one of the files is missing\")\n",
    "            continue\n",
    "\n",
    "        # Load lengths\n",
    "        npy_len = np.load(npy_path).shape[0]\n",
    "        jsonl_len = count_jsonl(jsonl_path)\n",
    "\n",
    "        if npy_len == jsonl_len:\n",
    "            print(f\"[OK] {name} -> npy={npy_len}, jsonl={jsonl_len}\")\n",
    "        else:\n",
    "            print(f\"[MISMATCH] {name} -> npy={npy_len}, jsonl={jsonl_len}\")\n",
    "\n",
    "# 전체 폴더 검사\n",
    "for d in gpu_dirs:\n",
    "    if os.path.exists(d):\n",
    "        check_folder(d)\n",
    "    else:\n",
    "        print(f\"Folder not found: {d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8dee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] vector_paragraphs_gpu0: 91 files\n",
      "[SKIP] vector_paragraphs_gpu1/checkpoint.json 없음.\n",
      "[SKIP] vector_paragraphs_gpu2/checkpoint.json 없음.\n",
      "[SKIP] vector_paragraphs_gpu3/checkpoint.json 없음.\n",
      "\n",
      "[WRITE] 병합 checkpoint 저장 완료: vector_paragraphs_gpu0/checkpoint.json\n",
      "총 파일 개수: 91\n",
      "[SKIP] vector_paragraphs_gpu1/checkpoint.json 없음\n",
      "[SKIP] vector_paragraphs_gpu2/checkpoint.json 없음\n",
      "[SKIP] vector_paragraphs_gpu3/checkpoint.json 없음\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'vector_paragraphs_gpu1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# 3. gpu1/2/3의 모든 파일을 gpu0으로 이동\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m gpu_dirs[\u001b[32m1\u001b[39m:]:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     58\u001b[39m         src = os.path.join(d, fname)\n\u001b[32m     59\u001b[39m         dst = os.path.join(target_dir, fname)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'vector_paragraphs_gpu1'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "gpu_dirs = [\n",
    "    \"vector_paragraphs_gpu0\",\n",
    "    \"vector_paragraphs_gpu1\",\n",
    "    \"vector_paragraphs_gpu2\",\n",
    "    \"vector_paragraphs_gpu3\",\n",
    "]\n",
    "\n",
    "target_dir = \"vector_paragraphs_gpu0\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1. checkpoint.json 병합\n",
    "# -----------------------------\n",
    "merged_processed = set()\n",
    "\n",
    "for d in gpu_dirs:\n",
    "    ckpt_path = os.path.join(d, \"checkpoint.json\")\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        print(f\"[SKIP] {ckpt_path} 없음.\")\n",
    "        continue\n",
    "\n",
    "    with open(ckpt_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    processed = data.get(\"processed_files\", [])\n",
    "    merged_processed.update(processed)\n",
    "    print(f\"[LOAD] {d}: {len(processed)} files\")\n",
    "\n",
    "# 정렬하여 병합 파일 생성\n",
    "merged_list = sorted(list(merged_processed))\n",
    "output_ckpt = os.path.join(target_dir, \"checkpoint.json\")\n",
    "\n",
    "with open(output_ckpt, \"w\") as f:\n",
    "    json.dump({\"processed_files\": merged_list}, f, indent=2)\n",
    "\n",
    "print(f\"\\n[WRITE] 병합 checkpoint 저장 완료: {output_ckpt}\")\n",
    "print(f\"총 파일 개수: {len(merged_list)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. gpu1/2/3의 checkpoint.json 삭제\n",
    "# -----------------------------\n",
    "for d in gpu_dirs[1:]:\n",
    "    ckpt_path = os.path.join(d, \"checkpoint.json\")\n",
    "    if os.path.exists(ckpt_path):\n",
    "        os.remove(ckpt_path)\n",
    "        print(f\"[DELETE] {ckpt_path} 삭제 완료\")\n",
    "    else:\n",
    "        print(f\"[SKIP] {ckpt_path} 없음\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. gpu1/2/3의 모든 파일을 gpu0으로 이동\n",
    "# -----------------------------\n",
    "for d in gpu_dirs[1:]:\n",
    "    for fname in os.listdir(d):\n",
    "        src = os.path.join(d, fname)\n",
    "        dst = os.path.join(target_dir, fname)\n",
    "\n",
    "        # 충돌 방지를 위해 중복 파일이 있을 경우 이름 변경\n",
    "        if os.path.exists(dst):\n",
    "            base, ext = os.path.splitext(fname)\n",
    "            new_name = f\"{base}_from_{os.path.basename(d)}{ext}\"\n",
    "            dst = os.path.join(target_dir, new_name)\n",
    "            print(f\"[RENAME] {fname} → {new_name}\")\n",
    "\n",
    "        shutil.move(src, dst)\n",
    "        print(f\"[MOVE] {src} → {dst}\")\n",
    "\n",
    "    print(f\"[CLEAR] {d} 폴더 파일 이동 완료\")\n",
    "\n",
    "print(\"\\n[FINISHED] 모든 병합·삭제·이동 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
