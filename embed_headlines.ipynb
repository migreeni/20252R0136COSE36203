{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정\n",
    "MODEL_NAME = \"BAAI/bge-large-en-v1.5\"\n",
    "DATA_DIR = Path(\"guardian_top100_scraping\")\n",
    "OUTPUT_DIR = Path(\"vector_headlines\")\n",
    "BATCH_SIZE = 32\n",
    "CHECKPOINT_FILE = OUTPUT_DIR / \"checkpoint.json\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Model과 Tokenizer load\n",
    "print(\"Loading model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_person_name(filename):\n",
    "    \"\"\"파일명에서 person 이름 추출 (예: alex_morgan.jsonl -> alex_morgan)\"\"\"\n",
    "    return filename.stem\n",
    "\n",
    "def parse_pub_date(web_pub_date):\n",
    "    \"\"\"webPublicationDate를 YYYY_MM_DD 형식으로 변환\"\"\"\n",
    "    dt = datetime.fromisoformat(web_pub_date.replace('Z', '+00:00'))\n",
    "    return dt.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_embeddings(texts, batch_size=32):\n",
    "    \"\"\"Batch 단위로 embedding 생성\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoded = tokenizer(batch, padding=True, truncation=True, \n",
    "                          max_length=512, return_tensors='pt')\n",
    "        encoded = {k: v.cuda() for k, v in encoded.items()}\n",
    "        \n",
    "        # Generate embeddings\n",
    "        outputs = model(**encoded)\n",
    "        # CLS token embedding 사용\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Normalize\n",
    "        batch_embeddings = torch.nn.functional.normalize(batch_embeddings, p=2, dim=1)\n",
    "        \n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 확인\n",
    "processed_files = set()\n",
    "if CHECKPOINT_FILE.exists():\n",
    "    with open(CHECKPOINT_FILE, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "        processed_files = set(checkpoint.get('processed_files', []))\n",
    "        print(f\"Checkpoint found: {len(processed_files)} files already processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to process: 100\n"
     ]
    }
   ],
   "source": [
    "# 모든 .jsonl 파일 수집\n",
    "jsonl_files = sorted([f for f in DATA_DIR.glob(\"*.jsonl\") if f.name not in processed_files])\n",
    "print(f\"Total files to process: {len(jsonl_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/100] Processing: alex_morgan\n",
      "  → Generating embeddings for 5833 headlines...\n",
      "  ✓ Done! (Total: 5833 headlines processed)\n",
      "\n",
      "[2/100] Processing: alicia_keys\n",
      "  → Generating embeddings for 2545 headlines...\n",
      "  ✓ Done! (Total: 8378 headlines processed)\n",
      "\n",
      "[3/100] Processing: andres_manuel_lopez\n",
      "  → Generating embeddings for 3247 headlines...\n",
      "  ✓ Done! (Total: 11625 headlines processed)\n",
      "\n",
      "[4/100] Processing: ann_mckee\n",
      "  → Generating embeddings for 2467 headlines...\n",
      "  ✓ Done! (Total: 14092 headlines processed)\n",
      "\n",
      "[5/100] Processing: ashley_graham\n",
      "  → Generating embeddings for 5074 headlines...\n",
      "  ✓ Done! (Total: 19166 headlines processed)\n",
      "\n",
      "[6/100] Processing: barbara_lynch\n",
      "  → Generating embeddings for 3256 headlines...\n",
      "  ✓ Done! (Total: 22422 headlines processed)\n",
      "\n",
      "[7/100] Processing: barbara_rae_venter\n",
      "  → Generating embeddings for 2635 headlines...\n",
      "  ✓ Done! (Total: 25057 headlines processed)\n",
      "\n",
      "[8/100] Processing: barry_jenkins\n",
      "  → Generating embeddings for 6003 headlines...\n",
      "  ✓ Done! (Total: 31060 headlines processed)\n",
      "\n",
      "[9/100] Processing: benjamin_netanyahu\n",
      "  → Generating embeddings for 3248 headlines...\n",
      "  ✓ Done! (Total: 34308 headlines processed)\n",
      "\n",
      "[10/100] Processing: bernard_tyson\n",
      "  → Generating embeddings for 2715 headlines...\n",
      "  ✓ Done! (Total: 37023 headlines processed)\n",
      "\n",
      "[11/100] Processing: bob_bland\n",
      "  → Generating embeddings for 3109 headlines...\n",
      "  ✓ Done! (Total: 40132 headlines processed)\n",
      "\n",
      "[12/100] Processing: bob_ferguson\n",
      "  → Generating embeddings for 3924 headlines...\n",
      "  ✓ Done! (Total: 44056 headlines processed)\n",
      "\n",
      "[13/100] Processing: carl_june\n",
      "  → Generating embeddings for 2318 headlines...\n",
      "  ✓ Done! (Total: 46374 headlines processed)\n",
      "\n",
      "[14/100] Processing: chance_the_rapper\n",
      "  → Generating embeddings for 2793 headlines...\n",
      "  ✓ Done! (Total: 49167 headlines processed)\n",
      "\n",
      "[15/100] Processing: chip_gaines\n",
      "  → Generating embeddings for 3115 headlines...\n",
      "  ✓ Done! (Total: 52282 headlines processed)\n",
      "\n",
      "[16/100] Processing: chloe_kim\n",
      "  → Generating embeddings for 5801 headlines...\n",
      "  ✓ Done! (Total: 58083 headlines processed)\n",
      "\n",
      "[17/100] Processing: christine_blasey_ford\n",
      "  → Generating embeddings for 5057 headlines...\n",
      "  ✓ Done! (Total: 63140 headlines processed)\n",
      "\n",
      "[18/100] Processing: christopher_wylie\n",
      "  → Generating embeddings for 6043 headlines...\n",
      "  ✓ Done! (Total: 69183 headlines processed)\n",
      "\n",
      "[19/100] Processing: chuck_schumer\n",
      "  → Generating embeddings for 2254 headlines...\n",
      "  ✓ Done! (Total: 71437 headlines processed)\n",
      "\n",
      "[20/100] Processing: cindy_holland\n",
      "  → Generating embeddings for 2431 headlines...\n",
      "  ✓ Done! (Total: 73868 headlines processed)\n",
      "\n",
      "[21/100] Processing: colin_kaepernick\n",
      "  → Generating embeddings for 3327 headlines...\n",
      "  ✓ Done! (Total: 77195 headlines processed)\n",
      "\n",
      "[22/100] Processing: david_hogg\n",
      "  → Generating embeddings for 2274 headlines...\n",
      "  ✓ Done! (Total: 79469 headlines processed)\n",
      "\n",
      "[23/100] Processing: donald_trump\n",
      "  → Generating embeddings for 26542 headlines...\n",
      "  ✓ Done! (Total: 106011 headlines processed)\n",
      "\n",
      "[24/100] Processing: elizabeth_diller\n",
      "  → Generating embeddings for 5454 headlines...\n",
      "  ✓ Done! (Total: 111465 headlines processed)\n",
      "\n",
      "[25/100] Processing: elizabeth_warren\n",
      "  → Generating embeddings for 8476 headlines...\n",
      "  ✓ Done! (Total: 119941 headlines processed)\n",
      "\n",
      "[26/100] Processing: emilia_clarke\n",
      "  → Generating embeddings for 3857 headlines...\n",
      "  ✓ Done! (Total: 123798 headlines processed)\n",
      "\n",
      "[27/100] Processing: emily_comer\n",
      "  → Generating embeddings for 3693 headlines...\n",
      "  ✓ Done! (Total: 127491 headlines processed)\n",
      "\n",
      "[28/100] Processing: emma_gonzalez\n",
      "  → Generating embeddings for 5232 headlines...\n",
      "  ✓ Done! (Total: 132723 headlines processed)\n",
      "\n",
      "[29/100] Processing: emma_stone\n",
      "  → Generating embeddings for 5045 headlines...\n",
      "  ✓ Done! (Total: 137768 headlines processed)\n",
      "\n",
      "[30/100] Processing: emmanuel_macron\n",
      "  → Generating embeddings for 3864 headlines...\n",
      "  ✓ Done! (Total: 141632 headlines processed)\n",
      "\n",
      "[31/100] Processing: gavin_grimm\n",
      "  → Generating embeddings for 2417 headlines...\n",
      "  ✓ Done! (Total: 144049 headlines processed)\n",
      "\n",
      "[32/100] Processing: glenda_gray\n",
      "  → Generating embeddings for 2278 headlines...\n",
      "  ✓ Done! (Total: 146327 headlines processed)\n",
      "\n",
      "[33/100] Processing: glenn_close\n",
      "  → Generating embeddings for 2646 headlines...\n",
      "  ✓ Done! (Total: 148973 headlines processed)\n",
      "\n",
      "[34/100] Processing: guillermo_del_toro\n",
      "  → Generating embeddings for 2966 headlines...\n",
      "  ✓ Done! (Total: 151939 headlines processed)\n",
      "\n",
      "[35/100] Processing: he_jiankui\n",
      "  → Generating embeddings for 2509 headlines...\n",
      "  ✓ Done! (Total: 154448 headlines processed)\n",
      "\n",
      "[36/100] Processing: imran_khan\n",
      "  → Generating embeddings for 4470 headlines...\n",
      "  ✓ Done! (Total: 158918 headlines processed)\n",
      "\n",
      "[37/100] Processing: indya_moore\n",
      "  → Generating embeddings for 4346 headlines...\n",
      "  ✓ Done! (Total: 163264 headlines processed)\n",
      "\n",
      "[38/100] Processing: ivanka_trump\n",
      "  → Generating embeddings for 8137 headlines...\n",
      "  ✓ Done! (Total: 171401 headlines processed)\n",
      "\n",
      "[39/100] Processing: jane_goodall\n",
      "  → Generating embeddings for 5113 headlines...\n",
      "  ✓ Done! (Total: 176514 headlines processed)\n",
      "\n",
      "[40/100] Processing: janet_mock\n",
      "  → Generating embeddings for 3141 headlines...\n",
      "  ✓ Done! (Total: 179655 headlines processed)\n",
      "\n",
      "[41/100] Processing: jason_blum\n",
      "  → Generating embeddings for 5277 headlines...\n",
      "  ✓ Done! (Total: 184932 headlines processed)\n",
      "\n",
      "[42/100] Processing: jay_oneal\n",
      "  → Generating embeddings for 3077 headlines...\n",
      "  ✓ Done! (Total: 188009 headlines processed)\n",
      "\n",
      "[43/100] Processing: jean_liu\n",
      "  → Generating embeddings for 6101 headlines...\n",
      "  ✓ Done! (Total: 194110 headlines processed)\n",
      "\n",
      "[44/100] Processing: jeanne_gang\n",
      "  → Generating embeddings for 4582 headlines...\n",
      "  ✓ Done! (Total: 198692 headlines processed)\n",
      "\n",
      "[45/100] Processing: jeff_bezos\n",
      "  → Generating embeddings for 4935 headlines...\n",
      "  ✓ Done! (Total: 203627 headlines processed)\n",
      "\n",
      "[46/100] Processing: jeff_sessions\n",
      "  → Generating embeddings for 8688 headlines...\n",
      "  ✓ Done! (Total: 212315 headlines processed)\n",
      "\n",
      "[47/100] Processing: jennifer_hyman\n",
      "  → Generating embeddings for 3198 headlines...\n",
      "  ✓ Done! (Total: 215513 headlines processed)\n",
      "\n",
      "[48/100] Processing: jennifer_lopez\n",
      "  → Generating embeddings for 3790 headlines...\n",
      "  ✓ Done! (Total: 219303 headlines processed)\n",
      "\n",
      "[49/100] Processing: jerome_powell\n",
      "  → Generating embeddings for 2436 headlines...\n",
      "  ✓ Done! (Total: 221739 headlines processed)\n",
      "\n",
      "[50/100] Processing: jesmyn_ward\n",
      "  → Generating embeddings for 3750 headlines...\n",
      "  ✓ Done! (Total: 225489 headlines processed)\n",
      "\n",
      "[51/100] Processing: jian_wei_pan\n",
      "  → Generating embeddings for 3397 headlines...\n",
      "  ✓ Done! (Total: 228886 headlines processed)\n",
      "\n",
      "[52/100] Processing: jimmy_kimmel\n",
      "  → Generating embeddings for 3652 headlines...\n",
      "  ✓ Done! (Total: 232538 headlines processed)\n",
      "\n",
      "[53/100] Processing: john_legend\n",
      "  → Generating embeddings for 5283 headlines...\n",
      "  ✓ Done! (Total: 237821 headlines processed)\n",
      "\n",
      "[54/100] Processing: john_lewis\n",
      "  → Generating embeddings for 4676 headlines...\n",
      "  ✓ Done! (Total: 242497 headlines processed)\n",
      "\n",
      "[55/100] Processing: jordan_peele\n",
      "  → Generating embeddings for 5471 headlines...\n",
      "  ✓ Done! (Total: 247968 headlines processed)\n",
      "\n",
      "[56/100] Processing: jose_andres\n",
      "  → Generating embeddings for 2788 headlines...\n",
      "  ✓ Done! (Total: 250756 headlines processed)\n",
      "\n",
      "[57/100] Processing: jr_artist\n",
      "  → Generating embeddings for 3592 headlines...\n",
      "  ✓ Done! (Total: 254348 headlines processed)\n",
      "\n",
      "[58/100] Processing: juan_guaido\n",
      "  → Generating embeddings for 2654 headlines...\n",
      "  ✓ Done! (Total: 257002 headlines processed)\n",
      "\n",
      "[59/100] Processing: juan_manuel_santos\n",
      "  → Generating embeddings for 5052 headlines...\n",
      "  ✓ Done! (Total: 262054 headlines processed)\n",
      "\n",
      "[60/100] Processing: judy_chicago\n",
      "  → Generating embeddings for 4165 headlines...\n",
      "  ✓ Done! (Total: 266219 headlines processed)\n",
      "\n",
      "[61/100] Processing: julian_assange\n",
      "  → Generating embeddings for 4010 headlines...\n",
      "  ✓ Done! (Total: 270229 headlines processed)\n",
      "\n",
      "[62/100] Processing: justin_trudeau\n",
      "  → Generating embeddings for 4983 headlines...\n",
      "  ✓ Done! (Total: 275212 headlines processed)\n",
      "\n",
      "[63/100] Processing: kerry_james_marshall\n",
      "  → Generating embeddings for 3634 headlines...\n",
      "  ✓ Done! (Total: 278846 headlines processed)\n",
      "\n",
      "[64/100] Processing: kim_jong_un\n",
      "  → Generating embeddings for 6121 headlines...\n",
      "  ✓ Done! (Total: 284967 headlines processed)\n",
      "\n",
      "[65/100] Processing: mahershala_ali\n",
      "  → Generating embeddings for 4835 headlines...\n",
      "  ✓ Done! (Total: 289802 headlines processed)\n",
      "\n",
      "[66/100] Processing: margaret_atwood\n",
      "  → Generating embeddings for 5393 headlines...\n",
      "  ✓ Done! (Total: 295195 headlines processed)\n",
      "\n",
      "[67/100] Processing: margot_robbie\n",
      "  → Generating embeddings for 2375 headlines...\n",
      "  ✓ Done! (Total: 297570 headlines processed)\n",
      "\n",
      "[68/100] Processing: maria_ressa\n",
      "  → Generating embeddings for 3333 headlines...\n",
      "  ✓ Done! (Total: 300903 headlines processed)\n",
      "\n",
      "[69/100] Processing: mauricio_macri\n",
      "  → Generating embeddings for 2261 headlines...\n",
      "  ✓ Done! (Total: 303164 headlines processed)\n",
      "\n",
      "[70/100] Processing: maxine_waters\n",
      "  → Generating embeddings for 5048 headlines...\n",
      "  ✓ Done! (Total: 308212 headlines processed)\n",
      "\n",
      "[71/100] Processing: michelle_obama\n",
      "  → Generating embeddings for 3271 headlines...\n",
      "  ✓ Done! (Total: 311483 headlines processed)\n",
      "\n",
      "[72/100] Processing: millie_bobby_brown\n",
      "  → Generating embeddings for 2342 headlines...\n",
      "  ✓ Done! (Total: 313825 headlines processed)\n",
      "\n",
      "[73/100] Processing: mirian_g\n",
      "  → Generating embeddings for 4096 headlines...\n",
      "  ✓ Done! (Total: 317921 headlines processed)\n",
      "\n",
      "[74/100] Processing: mohamed_bin_zayed\n",
      "  → Generating embeddings for 5971 headlines...\n",
      "  ✓ Done! (Total: 323892 headlines processed)\n",
      "\n",
      "[75/100] Processing: mohamed_salah\n",
      "  → Generating embeddings for 2668 headlines...\n",
      "  ✓ Done! (Total: 326560 headlines processed)\n",
      "\n",
      "[76/100] Processing: mohammed_bin_salman\n",
      "  → Generating embeddings for 5596 headlines...\n",
      "  ✓ Done! (Total: 332156 headlines processed)\n",
      "\n",
      "[77/100] Processing: moon_jae_in\n",
      "  → Generating embeddings for 4382 headlines...\n",
      "  ✓ Done! (Total: 336538 headlines processed)\n",
      "\n",
      "[78/100] Processing: nancy_pelosi\n",
      "  → Generating embeddings for 2392 headlines...\n",
      "  ✓ Done! (Total: 338930 headlines processed)\n",
      "\n",
      "[79/100] Processing: pat_mcgrath\n",
      "  → Generating embeddings for 3367 headlines...\n",
      "  ✓ Done! (Total: 342297 headlines processed)\n",
      "\n",
      "[80/100] Processing: pope_francis\n",
      "  → Generating embeddings for 4647 headlines...\n",
      "  ✓ Done! (Total: 346944 headlines processed)\n",
      "\n",
      "[81/100] Processing: prince_harry\n",
      "  → Generating embeddings for 6213 headlines...\n",
      "  ✓ Done! (Total: 353157 headlines processed)\n",
      "\n",
      "[82/100] Processing: robert_mueller\n",
      "  → Generating embeddings for 2975 headlines...\n",
      "  ✓ Done! (Total: 356132 headlines processed)\n",
      "\n",
      "[83/100] Processing: roger_federer\n",
      "  → Generating embeddings for 4373 headlines...\n",
      "  ✓ Done! (Total: 360505 headlines processed)\n",
      "\n",
      "[84/100] Processing: ruth_davidson\n",
      "  → Generating embeddings for 3696 headlines...\n",
      "  ✓ Done! (Total: 364201 headlines processed)\n",
      "\n",
      "[85/100] Processing: ryan_coogler\n",
      "  → Generating embeddings for 7442 headlines...\n",
      "  ✓ Done! (Total: 371643 headlines processed)\n",
      "\n",
      "[86/100] Processing: ryan_murphy\n",
      "  → Generating embeddings for 10453 headlines...\n",
      "  ✓ Done! (Total: 382096 headlines processed)\n",
      "\n",
      "[87/100] Processing: ryan_reynolds\n",
      "  → Generating embeddings for 8467 headlines...\n",
      "  ✓ Done! (Total: 390563 headlines processed)\n",
      "\n",
      "[88/100] Processing: sadiq_khan\n",
      "  → Generating embeddings for 4420 headlines...\n",
      "  ✓ Done! (Total: 394983 headlines processed)\n",
      "\n",
      "[89/100] Processing: samantha_bee\n",
      "  → Generating embeddings for 2267 headlines...\n",
      "  ✓ Done! (Total: 397250 headlines processed)\n",
      "\n",
      "[90/100] Processing: sandra_day_oconnor\n",
      "  → Generating embeddings for 3693 headlines...\n",
      "  ✓ Done! (Total: 400943 headlines processed)\n",
      "\n",
      "[91/100] Processing: sean_hannity\n",
      "  → Generating embeddings for 5332 headlines...\n",
      "  ✓ Done! (Total: 406275 headlines processed)\n",
      "\n",
      "[92/100] Processing: spike_lee\n",
      "  → Generating embeddings for 2341 headlines...\n",
      "  ✓ Done! (Total: 408616 headlines processed)\n",
      "\n",
      "[93/100] Processing: sterling_brown\n",
      "  → Generating embeddings for 4013 headlines...\n",
      "  ✓ Done! (Total: 412629 headlines processed)\n",
      "\n",
      "[94/100] Processing: taylor_swift\n",
      "  → Generating embeddings for 3768 headlines...\n",
      "  ✓ Done! (Total: 416397 headlines processed)\n",
      "\n",
      "[95/100] Processing: theresa_may\n",
      "  → Generating embeddings for 22188 headlines...\n",
      "  ✓ Done! (Total: 438585 headlines processed)\n",
      "\n",
      "[96/100] Processing: tiger_woods\n",
      "  → Generating embeddings for 4413 headlines...\n",
      "  ✓ Done! (Total: 442998 headlines processed)\n",
      "\n",
      "[97/100] Processing: trevor_noah\n",
      "  → Generating embeddings for 3191 headlines...\n",
      "  ✓ Done! (Total: 446189 headlines processed)\n",
      "\n",
      "[98/100] Processing: viola_davis\n",
      "  → Generating embeddings for 6075 headlines...\n",
      "  ✓ Done! (Total: 452264 headlines processed)\n",
      "\n",
      "[99/100] Processing: vladimir_putin\n",
      "  → Generating embeddings for 4958 headlines...\n",
      "  ✓ Done! (Total: 457222 headlines processed)\n",
      "\n",
      "[100/100] Processing: xi_jinping\n",
      "  → Generating embeddings for 4048 headlines...\n",
      "  ✓ Done! (Total: 461270 headlines processed)\n",
      "\n",
      "Combining all embeddings...\n",
      "Final embeddings shape: (461270, 1024)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 수집 및 embedding 생성 (인물별로 처리)\n",
    "all_embeddings = []\n",
    "all_metadata = []\n",
    "\n",
    "for idx, file_path in enumerate(jsonl_files):\n",
    "    person = extract_person_name(file_path)\n",
    "    print(f\"\\n[{idx+1}/{len(jsonl_files)}] Processing: {person}\")\n",
    "    \n",
    "    # 파일에서 기사 읽기\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        articles = [json.loads(line) for line in f]\n",
    "    \n",
    "    # 현재 인물의 headline과 metadata 추출\n",
    "    person_headlines = []\n",
    "    person_metadata = []\n",
    "    \n",
    "    for article in articles:\n",
    "        headline = article.get('headline', '')\n",
    "        if headline:  # headline이 있는 경우만 처리\n",
    "            person_headlines.append(headline)\n",
    "            person_metadata.append({\n",
    "                'person': person,\n",
    "                'article_id': article.get('id', ''),\n",
    "                'pub_date': parse_pub_date(article.get('webPublicationDate', '')),\n",
    "                'headline': headline\n",
    "            })\n",
    "    \n",
    "    # 현재 인물의 embedding 생성\n",
    "    if person_headlines:\n",
    "        print(f\"  → Generating embeddings for {len(person_headlines)} headlines...\")\n",
    "        person_embeddings = generate_embeddings(person_headlines, batch_size=BATCH_SIZE)\n",
    "        all_embeddings.append(person_embeddings)\n",
    "        all_metadata.extend(person_metadata)\n",
    "        print(f\"  ✓ Done! (Total: {len(all_metadata)} headlines processed)\")\n",
    "    \n",
    "    # Checkpoint 업데이트\n",
    "    processed_files.add(file_path.name)\n",
    "    with open(CHECKPOINT_FILE, 'w') as f:\n",
    "        json.dump({'processed_files': list(processed_files)}, f)\n",
    "\n",
    "# 모든 embeddings 합치기\n",
    "print(f\"\\nCombining all embeddings...\")\n",
    "embeddings = np.vstack(all_embeddings)\n",
    "print(f\"Final embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results...\n",
      "Saved: vector_headlines/embeddings.npy\n",
      "Saved: vector_headlines/metadata.jsonl\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# 결과 저장\n",
    "print(\"\\nSaving results...\")\n",
    "\n",
    "# embeddings.npy 저장\n",
    "np.save(OUTPUT_DIR / \"embeddings.npy\", embeddings)\n",
    "print(f\"Saved: {OUTPUT_DIR / 'embeddings.npy'}\")\n",
    "\n",
    "# metadata.jsonl 저장\n",
    "with open(OUTPUT_DIR / \"metadata.jsonl\", 'w', encoding='utf-8') as f:\n",
    "    for meta in all_metadata:\n",
    "        f.write(json.dumps(meta, ensure_ascii=False) + '\\n')\n",
    "print(f\"Saved: {OUTPUT_DIR / 'metadata.jsonl'}\")\n",
    "\n",
    "# Checkpoint 삭제 (완료되었으므로)\n",
    "if CHECKPOINT_FILE.exists():\n",
    "    CHECKPOINT_FILE.unlink()\n",
    "\n",
    "print(\"\\nAll done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
