{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHnDibxQeOWz"
      },
      "source": [
        "### **Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94BbcRQ-eJae"
      },
      "source": [
        "**0. Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bm3z6s5ObJin"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOYzkY32bww4"
      },
      "source": [
        "**1. 경로 설정**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dl0U29klbyyG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Source: ../feature_datasets\n",
            "Output Path: results_lr\n"
          ]
        }
      ],
      "source": [
        "# DATA_DIR = Path(\"/content/drive/MyDrive/COSE362/data/feature_engineering\")\n",
        "# OUTPUT_DIR = Path(\"/content/drive/MyDrive/COSE362/data/prediction_output\")\n",
        "DATA_DIR = Path(\"../feature_datasets\")\n",
        "OUTPUT_DIR = Path(\"results_lr\")\n",
        "RESULTS_DIR = OUTPUT_DIR / \"results\"  \n",
        "\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True) \n",
        "\n",
        "\n",
        "\n",
        "print(f\"Data Source: {DATA_DIR}\")\n",
        "print(f\"Output Path: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvByCANab0-K"
      },
      "source": [
        "**2. 데이터 로드**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aUEGo0z2b2Ro"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Parquet 파일 로드\n",
        "    \"\"\"\n",
        "    print(f\"Loading {file_path.name}...\")\n",
        "    df = pd.read_parquet(file_path)\n",
        "    \n",
        "    # 날짜순 정렬\n",
        "    if 'date_index' in df.columns:\n",
        "        df = df.sort_values('date_index').reset_index(drop=True)\n",
        "    \n",
        "    # ========================================\n",
        "    # pub_date → Date 변환\n",
        "    # ========================================\n",
        "    if 'pub_date' in df.columns:\n",
        "        # pub_date 형식: '2019_12_30' (언더스코어로 구분)\n",
        "        df['Date'] = pd.to_datetime(df['pub_date'], format='%Y_%m_%d')\n",
        "        print(f\"   Using 'pub_date' for Date column\")\n",
        "    else:\n",
        "        # pub_date가 없으면 임시 날짜 생성 (fallback)\n",
        "        print(\"   [Warning] No 'pub_date' found. Using default date range.\")\n",
        "        df['Date'] = pd.date_range(start='2017-01-01', periods=len(df), freq='D')\n",
        "    \n",
        "    print(f\"   Loaded {len(df)} rows, {len(df.columns)} columns\")\n",
        "    print(f\"   ✅ Date range: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB5E2PUyb8wH"
      },
      "source": [
        "**3. 전처리 & 가중치 생성 함수**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Go3h3xlb_n8"
      },
      "outputs": [],
      "source": [
        "def preprocess_and_split(df, target_col='value'):\n",
        "    \"\"\"\n",
        "    전처리 및 Train/Valid/Test 분할\n",
        "    \"\"\"\n",
        "    \n",
        "    # ========================================\n",
        "    # 1. Target 생성\n",
        "    # ========================================\n",
        "    daily_prices = df[['date_index', target_col]].drop_duplicates().sort_values('date_index')\n",
        "    daily_prices['target'] = daily_prices[target_col].shift(-1)\n",
        "    \n",
        "    df = df.drop(columns=['target'], errors='ignore')\n",
        "    df = df.merge(daily_prices[['date_index', 'target']], on='date_index', how='left')\n",
        "    df = df.dropna(subset=['target'])\n",
        "    \n",
        "    print(f\"   After target creation: {len(df)} rows\")\n",
        "    \n",
        "    # ========================================\n",
        "    # 2. Sample Weight 계산\n",
        "    # ========================================\n",
        "    date_counts = df['date_index'].value_counts()\n",
        "    df['sample_weight'] = df['date_index'].map(lambda x: 1.0 / date_counts[x])\n",
        "    \n",
        "    print(f\"   Sample weights: min={df['sample_weight'].min():.4f}, \"\n",
        "          f\"max={df['sample_weight'].max():.4f}, mean={df['sample_weight'].mean():.4f}\")\n",
        "    \n",
        "    # ========================================\n",
        "    # 3. ✅ Date 먼저 추출 (split용)\n",
        "    # ========================================\n",
        "    if 'Date' not in df.columns:\n",
        "        raise ValueError(\"'Date' column not found in dataframe\")\n",
        "    \n",
        "    dates = df['Date'].copy()\n",
        "    \n",
        "    # ✅ 즉시 Date 컬럼 제거\n",
        "    df = df.drop(columns=['Date'])\n",
        "    \n",
        "    # ========================================\n",
        "    # 4. 드롭할 컬럼 정의\n",
        "    # ========================================\n",
        "    cols_to_drop = [\n",
        "        # 메타데이터\n",
        "        'person',\n",
        "        'person_id', \n",
        "        'article_id',\n",
        "        \n",
        "        # 날짜 (이미 제거됨)\n",
        "        'pub_date',\n",
        "        # 'Date',  ← 이미 위에서 제거했으므로 불필요\n",
        "        \n",
        "        # Target 관련\n",
        "        'value',\n",
        "        'target',     # y로 사용 (X에서만 제외)\n",
        "        \n",
        "        # Fear-Greed\n",
        "        'fg_value',\n",
        "        \n",
        "        # Weight\n",
        "        'sample_weight',\n",
        "    ]\n",
        "    \n",
        "    # 실제 존재하는 컬럼만 필터링\n",
        "    actual_drop = [c for c in cols_to_drop if c in df.columns]\n",
        "    print(f\"   Dropping columns: {actual_drop}\")\n",
        "    \n",
        "    # ========================================\n",
        "    # 5. X, y, weights 추출\n",
        "    # ========================================\n",
        "    X = df.drop(columns=actual_drop, errors='ignore')\n",
        "    y = df['target'].copy()\n",
        "    weights = df['sample_weight'].copy()\n",
        "    \n",
        "    # ✅ X에 datetime 컬럼이 없는지 확인\n",
        "    datetime_cols = X.select_dtypes(include=['datetime64']).columns.tolist()\n",
        "    if datetime_cols:\n",
        "        print(f\"   ⚠️ WARNING: Found datetime columns in X: {datetime_cols}\")\n",
        "        X = X.drop(columns=datetime_cols)\n",
        "        print(f\"   Removed datetime columns from X\")\n",
        "    \n",
        "    print(f\"   Feature columns ({len(X.columns)}): {list(X.columns[:10])}...\")\n",
        "    \n",
        "    # ========================================\n",
        "    # 6. Train/Valid/Test Split\n",
        "    # ========================================\n",
        "    train_mask = (dates <= '2018-12-31')\n",
        "    valid_mask = (dates >= '2019-01-01') & (dates <= '2019-06-30')\n",
        "    test_mask  = (dates >= '2019-07-01')\n",
        "    \n",
        "    print(f\"   Train: {train_mask.sum()} rows\")\n",
        "    print(f\"   Valid: {valid_mask.sum()} rows\")\n",
        "    print(f\"   Test:  {test_mask.sum()} rows\")\n",
        "    \n",
        "    return (\n",
        "        (X[train_mask], y[train_mask], weights[train_mask]),\n",
        "        (X[valid_mask], y[valid_mask], weights[valid_mask]),\n",
        "        (X[test_mask], y[test_mask], weights[test_mask], dates[test_mask])\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r6OTeYYcMpV"
      },
      "source": [
        "**4. 모델 튜닝 및 학습 함수**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A8iAvnx2cOed"
      },
      "outputs": [],
      "source": [
        "def train_linear_models(dataset_name, file_path):\n",
        "    \"\"\"\n",
        "    Linear, Ridge, Lasso Grid Search (alpha = [0.1, 1.0, 10.0])\n",
        "    총 7개 조합: Linear(1) + Ridge(3) + Lasso(3)\n",
        "    \n",
        "    ✅ 이미 결과 파일이 존재하면 스킵\n",
        "    \"\"\"\n",
        "    \n",
        "    # ========================================\n",
        "    # 0. ✅ 결과 파일 존재 여부 확인\n",
        "    # ========================================\n",
        "    output_path = RESULTS_DIR / f\"pred_linear_{dataset_name}.json\"\n",
        "    \n",
        "    if output_path.exists():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"⏭️  SKIPPING: {dataset_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"   Result already exists: {output_path.name}\")\n",
        "        \n",
        "        # ✅ 기존 결과 파일에서 MSE 읽기 (optional)\n",
        "        try:\n",
        "            with open(output_path, 'r') as f:\n",
        "                result_data = json.load(f)\n",
        "            \n",
        "            # MSE 계산 (저장된 예측값으로)\n",
        "            actuals = [item['actual'] for item in result_data]\n",
        "            preds = [item['predicted'] for item in result_data]\n",
        "            mse = mean_squared_error(actuals, preds)\n",
        "            \n",
        "            # 어떤 모델이었는지는 모르니 \"Cached\" 표시\n",
        "            print(f\"   ✅ Cached Test MSE: {mse:.4f}\")\n",
        "            \n",
        "            return \"Cached\", mse\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ⚠️ Warning: Could not read cached MSE: {e}\")\n",
        "            print(f\"   Re-running experiment...\")\n",
        "            # 에러 시 계속 진행 (아래 코드 실행)\n",
        "    \n",
        "    # ========================================\n",
        "    # 1. 데이터 로드 및 전처리\n",
        "    # ========================================\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing: {dataset_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    df = load_data(file_path)\n",
        "    \n",
        "    (X_train, y_train, w_train), \\\n",
        "    (X_valid, y_valid, w_valid), \\\n",
        "    (X_test, y_test, w_test, dates_test) = preprocess_and_split(df)\n",
        "    \n",
        "    del df\n",
        "    gc.collect()\n",
        "    \n",
        "    # ========================================\n",
        "    # 2. Grid Search 설정\n",
        "    # ========================================\n",
        "    alphas = [0.1]\n",
        "    \n",
        "    models_config = [\n",
        "        ('Linear', LinearRegression(), None),\n",
        "        ('Ridge', Ridge(), alphas),\n",
        "        ('Lasso', Lasso(max_iter=2000), alphas)\n",
        "    ]\n",
        "    \n",
        "    print(f\"   Grid Search Configuration:\")\n",
        "    print(f\"   - Linear: 1 combination\")\n",
        "    print(f\"   - Ridge: {len(alphas)} combinations (alphas={alphas})\")\n",
        "    print(f\"   - Lasso: {len(alphas)} combinations (alphas={alphas})\")\n",
        "    print(f\"   - Total: {1 + len(alphas)*2} combinations\\n\")\n",
        "    \n",
        "    # ========================================\n",
        "    # 3. Grid Search 실행\n",
        "    # ========================================\n",
        "    best_mse = float('inf')\n",
        "    best_model = None\n",
        "    best_info = \"\"\n",
        "    \n",
        "    for model_name, model_base, alpha_list in models_config:\n",
        "        \n",
        "        if alpha_list is None:\n",
        "            print(f\"   Training {model_name}...\")\n",
        "            \n",
        "            pipeline = Pipeline([\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('model', model_base)\n",
        "            ])\n",
        "            \n",
        "            pipeline.fit(X_train, y_train, model__sample_weight=w_train)\n",
        "            val_pred = pipeline.predict(X_valid)\n",
        "            val_mse = mean_squared_error(y_valid, val_pred)\n",
        "            \n",
        "            print(f\"      Valid MSE: {val_mse:.4f}\")\n",
        "            \n",
        "            if val_mse < best_mse:\n",
        "                best_mse = val_mse\n",
        "                best_model = pipeline\n",
        "                best_info = model_name\n",
        "        \n",
        "        else:\n",
        "            for alpha in alpha_list:\n",
        "                print(f\"   Training {model_name}(alpha={alpha})...\")\n",
        "                \n",
        "                if model_name == 'Ridge':\n",
        "                    current_model = Ridge(alpha=alpha)\n",
        "                else:\n",
        "                    current_model = Lasso(alpha=alpha, max_iter=2000)\n",
        "                \n",
        "                pipeline = Pipeline([\n",
        "                    ('scaler', StandardScaler()),\n",
        "                    ('model', current_model)\n",
        "                ])\n",
        "                \n",
        "                pipeline.fit(X_train, y_train, model__sample_weight=w_train)\n",
        "                val_pred = pipeline.predict(X_valid)\n",
        "                val_mse = mean_squared_error(y_valid, val_pred)\n",
        "                \n",
        "                print(f\"      Valid MSE: {val_mse:.4f}\")\n",
        "                \n",
        "                if val_mse < best_mse:\n",
        "                    best_mse = val_mse\n",
        "                    best_model = pipeline\n",
        "                    best_info = f\"{model_name}(alpha={alpha})\"\n",
        "    \n",
        "    # ========================================\n",
        "    # 4. Best Model 평가\n",
        "    # ========================================\n",
        "    print(f\"\\n   ✅ Best Model: {best_info}\")\n",
        "    print(f\"   ✅ Validation MSE: {best_mse:.4f}\")\n",
        "    \n",
        "    test_pred = best_model.predict(X_test)\n",
        "    test_mse = mean_squared_error(y_test, test_pred)\n",
        "    print(f\"   ✅ Test MSE: {test_mse:.4f}\")\n",
        "    \n",
        "    # ========================================\n",
        "    # 5. ✅ 결과 저장 (RESULTS_DIR)\n",
        "    # ========================================\n",
        "    result_data = []\n",
        "    for date, actual, pred in zip(dates_test, y_test, test_pred):\n",
        "        result_data.append({\n",
        "            \"date\": date.strftime('%Y-%m-%d'),\n",
        "            \"actual\": float(actual),\n",
        "            \"predicted\": float(pred)\n",
        "        })\n",
        "    \n",
        "    # ✅ RESULTS_DIR에 저장\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(result_data, f, indent=4)\n",
        "    \n",
        "    print(f\"   Saved predictions to: results/{output_path.name}\")\n",
        "    \n",
        "    # 메모리 정리\n",
        "    del X_train, y_train, X_valid, y_valid, X_test, y_test\n",
        "    gc.collect()\n",
        "    \n",
        "    return best_info, test_mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnBbrmCUcicE"
      },
      "source": [
        "**5. Main Execution Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "45F_IT8WcmcV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "BASELINE: Dataset A\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Processing: A\n",
            "============================================================\n",
            "Loading dataset_A.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 754 rows, 9 columns\n",
            "   ✅ Date range: 2017-01-03 to 2019-12-31\n",
            "   After target creation: 753 rows\n",
            "   Sample weights: min=1.0000, max=1.0000, mean=1.0000\n",
            "   Dropping columns: ['pub_date', 'value', 'target', 'sample_weight']\n",
            "   Feature columns (6): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']...\n",
            "   Train: 502 rows\n",
            "   Valid: 124 rows\n",
            "   Test:  127 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 820.8577\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 822.4023\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 816.4558\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 816.4558\n",
            "   ✅ Test MSE: 1015.6601\n",
            "   Saved predictions to: results/pred_linear_A.json\n",
            "\n",
            "============================================================\n",
            "Processing: B_headlines_pca\n",
            "============================================================\n",
            "Loading dataset_B_headlines_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 461270 rows, 317 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460915 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (310): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312535 rows\n",
            "   Valid: 76232 rows\n",
            "   Test:  72148 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 798.4752\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 800.4074\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 806.0708\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 798.4752\n",
            "   ✅ Test MSE: 1105.7667\n",
            "   Saved predictions to: results/pred_linear_B_headlines_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: B_headlines_orig\n",
            "============================================================\n",
            "Loading dataset_B_headlines_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 461270 rows, 1037 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460915 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1030): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312535 rows\n",
            "   Valid: 76232 rows\n",
            "   Test:  72148 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 816.6551\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 818.5220\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 807.3698\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 807.3698\n",
            "   ✅ Test MSE: 1098.6073\n",
            "   Saved predictions to: results/pred_linear_B_headlines_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: B_chunking_pca\n",
            "============================================================\n",
            "Loading dataset_B_chunking_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 257 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (250): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 794.9317\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 796.8562\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 807.0110\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 794.9317\n",
            "   ✅ Test MSE: 1104.6235\n",
            "   Saved predictions to: results/pred_linear_B_chunking_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: B_chunking_orig\n",
            "============================================================\n",
            "Loading dataset_B_chunking_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1037 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1030): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 819.5647\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 821.4187\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 809.4922\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 809.4922\n",
            "   ✅ Test MSE: 1099.9708\n",
            "   Saved predictions to: results/pred_linear_B_chunking_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: B_bodyText_pca\n",
            "============================================================\n",
            "Loading dataset_B_bodyText_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 204 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (197): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 791.5103\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 793.4175\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 806.9744\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 791.5103\n",
            "   ✅ Test MSE: 1096.2534\n",
            "   Saved predictions to: results/pred_linear_B_bodyText_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: B_bodyText_orig\n",
            "============================================================\n",
            "Loading dataset_B_bodyText_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1037 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1030): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 818.5216\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 820.2426\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 809.7451\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 809.7451\n",
            "   ✅ Test MSE: 1098.0591\n",
            "   Saved predictions to: results/pred_linear_B_bodyText_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: B_paragraphs_pca\n",
            "============================================================\n",
            "Loading dataset_B_paragraphs_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 221 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (214): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 792.1162\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 793.9999\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 806.6164\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 792.1162\n",
            "   ✅ Test MSE: 1101.5742\n",
            "   Saved predictions to: results/pred_linear_B_paragraphs_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: B_paragraphs_orig\n",
            "============================================================\n",
            "Loading dataset_B_paragraphs_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1037 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1030): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 818.1948\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 819.9905\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 810.1130\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 810.1130\n",
            "   ✅ Test MSE: 1102.7649\n",
            "   Saved predictions to: results/pred_linear_B_paragraphs_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: C_headlines_pca\n",
            "============================================================\n",
            "Loading dataset_C_headlines_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 461270 rows, 417 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460915 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (410): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312535 rows\n",
            "   Valid: 76232 rows\n",
            "   Test:  72148 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 798.7838\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 800.7146\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 806.3632\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 798.7838\n",
            "   ✅ Test MSE: 1105.7042\n",
            "   Saved predictions to: results/pred_linear_C_headlines_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: C_headlines_orig\n",
            "============================================================\n",
            "Loading dataset_C_headlines_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 461270 rows, 1137 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460915 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1130): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312535 rows\n",
            "   Valid: 76232 rows\n",
            "   Test:  72148 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 816.8026\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 818.6680\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 807.5392\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 807.5392\n",
            "   ✅ Test MSE: 1098.6348\n",
            "   Saved predictions to: results/pred_linear_C_headlines_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: C_chunking_pca\n",
            "============================================================\n",
            "Loading dataset_C_chunking_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 357 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (350): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 795.2185\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 797.1404\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 807.1960\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 795.2185\n",
            "   ✅ Test MSE: 1104.1838\n",
            "   Saved predictions to: results/pred_linear_C_chunking_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: C_chunking_orig\n",
            "============================================================\n",
            "Loading dataset_C_chunking_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1137 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1130): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 819.6958\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 821.5464\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 809.6170\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 809.6170\n",
            "   ✅ Test MSE: 1099.9154\n",
            "   Saved predictions to: results/pred_linear_C_chunking_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: C_bodyText_pca\n",
            "============================================================\n",
            "Loading dataset_C_bodyText_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 304 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (297): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 791.8669\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 793.7723\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 807.2092\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 791.8669\n",
            "   ✅ Test MSE: 1096.2036\n",
            "   Saved predictions to: results/pred_linear_C_bodyText_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: C_bodyText_orig\n",
            "============================================================\n",
            "Loading dataset_C_bodyText_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1137 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1130): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 818.9318\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 820.6545\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 809.9632\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 809.9632\n",
            "   ✅ Test MSE: 1098.0741\n",
            "   Saved predictions to: results/pred_linear_C_bodyText_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: C_paragraphs_pca\n",
            "============================================================\n",
            "Loading dataset_C_paragraphs_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 321 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (314): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 792.5827\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 794.4659\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 806.9728\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 792.5827\n",
            "   ✅ Test MSE: 1101.5813\n",
            "   Saved predictions to: results/pred_linear_C_paragraphs_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: C_paragraphs_orig\n",
            "============================================================\n",
            "Loading dataset_C_paragraphs_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1137 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1130): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 818.4856\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 820.2812\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 810.3309\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 810.3309\n",
            "   ✅ Test MSE: 1102.6769\n",
            "   Saved predictions to: results/pred_linear_C_paragraphs_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: D_headlines_pca\n",
            "============================================================\n",
            "Loading dataset_D_headlines_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 461270 rows, 423 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460915 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'fg_value', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (415): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312535 rows\n",
            "   Valid: 76232 rows\n",
            "   Test:  72148 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 720.4113\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 723.1764\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 732.8574\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 720.4113\n",
            "   ✅ Test MSE: 889.9465\n",
            "   Saved predictions to: results/pred_linear_D_headlines_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: D_headlines_orig\n",
            "============================================================\n",
            "Loading dataset_D_headlines_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 461270 rows, 1143 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460915 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'fg_value', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1135): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312535 rows\n",
            "   Valid: 76232 rows\n",
            "   Test:  72148 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 734.9941\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 737.6365\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 733.7830\n",
            "\n",
            "   ✅ Best Model: Lasso(alpha=0.1)\n",
            "   ✅ Validation MSE: 733.7830\n",
            "   ✅ Test MSE: 881.8738\n",
            "   Saved predictions to: results/pred_linear_D_headlines_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: D_chunking_pca\n",
            "============================================================\n",
            "Loading dataset_D_chunking_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 363 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'fg_value', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (355): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 716.7162\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 719.4991\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 734.1833\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 716.7162\n",
            "   ✅ Test MSE: 886.4355\n",
            "   Saved predictions to: results/pred_linear_D_chunking_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: D_chunking_orig\n",
            "============================================================\n",
            "Loading dataset_D_chunking_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1143 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'fg_value', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1135): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 728.1525\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 730.9150\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 734.8671\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 728.1525\n",
            "   ✅ Test MSE: 898.5955\n",
            "   Saved predictions to: results/pred_linear_D_chunking_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: D_bodyText_pca\n",
            "============================================================\n",
            "Loading dataset_D_bodyText_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 310 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'fg_value', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (302): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 712.2694\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 714.9723\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 733.0562\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 712.2694\n",
            "   ✅ Test MSE: 881.7619\n",
            "   Saved predictions to: results/pred_linear_D_bodyText_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: D_bodyText_orig\n",
            "============================================================\n",
            "Loading dataset_D_bodyText_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1143 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'fg_value', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1135): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 729.6031\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 732.1421\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 734.2109\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 729.6031\n",
            "   ✅ Test MSE: 895.5691\n",
            "   Saved predictions to: results/pred_linear_D_bodyText_orig.json\n",
            "\n",
            "============================================================\n",
            "Processing: D_paragraphs_pca\n",
            "============================================================\n",
            "Loading dataset_D_paragraphs_pca.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 327 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'fg_value', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (319): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'pca_0', 'pca_1', 'pca_2', 'pca_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 713.8517\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 716.5613\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 732.4633\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 713.8517\n",
            "   ✅ Test MSE: 886.3165\n",
            "   Saved predictions to: results/pred_linear_D_paragraphs_pca.json\n",
            "\n",
            "============================================================\n",
            "Processing: D_paragraphs_orig\n",
            "============================================================\n",
            "Loading dataset_D_paragraphs_orig.parquet...\n",
            "   Using 'pub_date' for Date column\n",
            "   Loaded 460722 rows, 1143 columns\n",
            "   ✅ Date range: 2017-01-01 to 2019-12-31\n",
            "   After target creation: 460368 rows\n",
            "   Sample weights: min=0.0006, max=0.0040, mean=0.0016\n",
            "   Dropping columns: ['person', 'person_id', 'article_id', 'pub_date', 'value', 'target', 'fg_value', 'sample_weight']\n",
            "   ⚠️ WARNING: Found datetime columns in X: ['article_date']\n",
            "   Removed datetime columns from X\n",
            "   Feature columns (1135): ['date_index', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'emb_0', 'emb_1', 'emb_2', 'emb_3']...\n",
            "   Train: 312185 rows\n",
            "   Valid: 76136 rows\n",
            "   Test:  72047 rows\n",
            "   Grid Search Configuration:\n",
            "   - Linear: 1 combination\n",
            "   - Ridge: 1 combinations (alphas=[0.1])\n",
            "   - Lasso: 1 combinations (alphas=[0.1])\n",
            "   - Total: 3 combinations\n",
            "\n",
            "   Training Linear...\n",
            "      Valid MSE: 730.1462\n",
            "   Training Ridge(alpha=0.1)...\n",
            "      Valid MSE: 732.7557\n",
            "   Training Lasso(alpha=0.1)...\n",
            "      Valid MSE: 735.2583\n",
            "\n",
            "   ✅ Best Model: Linear\n",
            "   ✅ Validation MSE: 730.1462\n",
            "   ✅ Test MSE: 896.3980\n",
            "   Saved predictions to: results/pred_linear_D_paragraphs_orig.json\n",
            "\n",
            "============================================================\n",
            "ALL TASKS COMPLETED\n",
            "============================================================\n",
            "\n",
            "Results saved to: results_lr/linear_evaluation_metrics.csv\n",
            "\n",
            "Top 10 Models by Test MSE:\n",
            "   Dataset      Method  Type        Best_Model     Test_MSE\n",
            "21       D    bodyText   pca            Linear   881.761903\n",
            "18       D   headlines  orig  Lasso(alpha=0.1)   881.873831\n",
            "23       D  paragraphs   pca            Linear   886.316460\n",
            "19       D    chunking   pca            Linear   886.435477\n",
            "17       D   headlines   pca            Linear   889.946503\n",
            "22       D    bodyText  orig            Linear   895.569087\n",
            "24       D  paragraphs  orig            Linear   896.398034\n",
            "20       D    chunking  orig            Linear   898.595455\n",
            "0        A           -     -  Lasso(alpha=0.1)  1015.660133\n",
            "13       C    bodyText   pca            Linear  1096.203566\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# Main Execution Loop\n",
        "# ========================================\n",
        "\n",
        "levels = ['B', 'C', 'D']\n",
        "methods = ['headlines', 'chunking', 'bodyText', 'paragraphs']\n",
        "types = ['pca', 'orig']\n",
        "\n",
        "metrics_list = []\n",
        "\n",
        "# Dataset A (Baseline)\n",
        "path_A = DATA_DIR / \"dataset_A.parquet\"\n",
        "if path_A.exists():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BASELINE: Dataset A\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    try:\n",
        "        info, mse = train_linear_models(\"A\", path_A)\n",
        "        metrics_list.append({\n",
        "            \"Dataset\": \"A\",\n",
        "            \"Method\": \"-\",\n",
        "            \"Type\": \"-\",\n",
        "            \"Best_Model\": info,\n",
        "            \"Test_MSE\": mse\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error on Dataset A: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        gc.collect()\n",
        "else:\n",
        "    print(f\"Warning: {path_A} not found. Skipping Dataset A.\")\n",
        "\n",
        "# Dataset B, C, D\n",
        "total_datasets = len(levels) * len(methods) * len(types)\n",
        "current = 0\n",
        "\n",
        "for level in levels:\n",
        "    for method in methods:\n",
        "        for dtype in types:\n",
        "            current += 1\n",
        "            fname = f\"dataset_{level}_{method}_{dtype}.parquet\"\n",
        "            fpath = DATA_DIR / fname\n",
        "            \n",
        "            if not fpath.exists():\n",
        "                print(f\"\\n[{current}/{total_datasets}] Skipping {fname}: File not found.\")\n",
        "                continue\n",
        "            \n",
        "            dname = f\"{level}_{method}_{dtype}\"\n",
        "            \n",
        "            try:\n",
        "                info, mse = train_linear_models(dname, fpath)\n",
        "                metrics_list.append({\n",
        "                    \"Dataset\": level,\n",
        "                    \"Method\": method,\n",
        "                    \"Type\": dtype,\n",
        "                    \"Best_Model\": info,\n",
        "                    \"Test_MSE\": mse\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"\\n❌ Error on {dname}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "            finally:\n",
        "                gc.collect()\n",
        "\n",
        "# ========================================\n",
        "# 최종 결과 정리 및 저장\n",
        "# ========================================\n",
        "final_df = pd.DataFrame(metrics_list).sort_values(\"Test_MSE\")\n",
        "\n",
        "# ✅ OUTPUT_DIR (results_lr/)에 CSV 저장\n",
        "csv_path = OUTPUT_DIR / \"linear_evaluation_metrics.csv\"\n",
        "final_df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ALL TASKS COMPLETED\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nResults saved to: {csv_path}\")\n",
        "print(f\"\\nTop 10 Models by Test MSE:\")\n",
        "print(final_df.head(10))\n",
        "\n",
        "# 10개 60분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlproject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
