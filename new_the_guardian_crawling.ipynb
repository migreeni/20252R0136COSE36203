{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['GUARDIAN_API_KEY'] = \"YOUR_API_KEY_HERE\"\n",
    "# os.environ['GUARDIAN_API_KEY'] = 'cfc29433-1765-41ac-8726-14d5ce438b9d' #원준\n",
    "os.environ['GUARDIAN_API_KEY'] = '77465cf2-e74d-4260-b796-7a9d2c829333' #규주\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0450cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: Setup & Config =====\n",
    "\n",
    "import os, re, json, time, pathlib\n",
    "from datetime import datetime, date\n",
    "from typing import Dict, List, Tuple, Iterable\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = os.getenv(\"GUARDIAN_API_KEY\", \"\").strip()\n",
    "assert API_KEY, \"Set GUARDIAN_API_KEY environment variable.\"\n",
    "\n",
    "BASE_SEARCH = \"https://content.guardianapis.com/search\"\n",
    "OUTPUT_COLS = [\n",
    "    \"id\",\"webPublicationDate\",\"headline\",\"trailText\",\"bodyText\",\n",
    "    \"webTitle\",\"webUrl\",\"apiUrl\",\"wordcount\"\n",
    "]\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    \"\"\"파일명으로 사용 가능한 slug 생성\"\"\"\n",
    "    s = re.sub(r'[^0-9A-Za-z]+', '_', s.lower()).strip('_')\n",
    "    return s or \"query\"\n",
    "\n",
    "def year_slices(start_date: str, end_date: str) -> List[Tuple[int, str, str]]:\n",
    "    \"\"\"날짜 범위를 연도별로 분할\"\"\"\n",
    "    sd = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    ed = datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "    assert sd <= ed, \"start_date must be <= end_date\"\n",
    "    out = []\n",
    "    y = sd.year\n",
    "    while y <= ed.year:\n",
    "        s = max(sd, date(y,1,1))\n",
    "        e = min(ed, date(y,12,31))\n",
    "        out.append((y, s.isoformat(), e.isoformat()))\n",
    "        y += 1\n",
    "    return out\n",
    "\n",
    "def guardian_get(params: Dict, max_retries: int = 6) -> Dict:\n",
    "    \"\"\"Guardian API 호출 (에러 시 자동 재시도)\"\"\"\n",
    "    p = dict(params)\n",
    "    p[\"api-key\"] = API_KEY\n",
    "    sleep = 1.5\n",
    "    for _ in range(max_retries):\n",
    "        r = requests.get(BASE_SEARCH, params=p, timeout=30)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()\n",
    "        if r.status_code in (429, 502, 503, 504):\n",
    "            time.sleep(sleep)\n",
    "            sleep *= 2\n",
    "            continue\n",
    "        r.raise_for_status()\n",
    "    raise RuntimeError(f\"Guardian API failed: {r.status_code} {r.text[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9031f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 2: Fetch & Save Functions =====\n",
    "\n",
    "def iter_results(q: str, from_date: str, to_date: str,\n",
    "                 query_fields=(\"headline\",\"body\"), page_size: int = 200) -> Iterable[Dict]:\n",
    "    \"\"\"모든 페이지의 검색 결과를 yield\"\"\"\n",
    "    params = {\n",
    "        \"q\": q.lower(),\n",
    "        \"from-date\": from_date,\n",
    "        \"to-date\": to_date,\n",
    "        \"page-size\": page_size,\n",
    "        \"order-by\": \"newest\",\n",
    "        \"use-date\": \"published\",\n",
    "        \"query-fields\": \",\".join(query_fields),\n",
    "        \"show-fields\": \"headline,trailText,bodyText,thumbnail,wordcount\",\n",
    "        \"show-tags\": \"all\",\n",
    "    }\n",
    "    js = guardian_get(params)\n",
    "    resp = js.get(\"response\", {})\n",
    "    pages = int(resp.get(\"pages\", 0)) or 0\n",
    "    \n",
    "    for it in resp.get(\"results\", []):\n",
    "        yield it\n",
    "    \n",
    "    for p in range(2, pages + 1):\n",
    "        params[\"page\"] = p\n",
    "        js = guardian_get(params)\n",
    "        for it in js.get(\"response\", {}).get(\"results\", []):\n",
    "            yield it\n",
    "\n",
    "def to_row(it: Dict) -> Dict:\n",
    "    \"\"\"검색 결과를 출력 스키마로 변환\"\"\"\n",
    "    f = it.get(\"fields\") or {}\n",
    "    return {\n",
    "        \"id\": it.get(\"id\"),\n",
    "        \"webPublicationDate\": it.get(\"webPublicationDate\"),\n",
    "        \"headline\": f.get(\"headline\"),\n",
    "        \"trailText\": f.get(\"trailText\"),\n",
    "        \"bodyText\": f.get(\"bodyText\"),\n",
    "        \"webTitle\": it.get(\"webTitle\"),\n",
    "        \"webUrl\": it.get(\"webUrl\"),\n",
    "        \"apiUrl\": it.get(\"apiUrl\"),\n",
    "        \"wordcount\": f.get(\"wordcount\"),\n",
    "    }\n",
    "\n",
    "def crawl_and_save(query: str, start_date: str, end_date: str,\n",
    "                   out_dir: str = \"guardian_raw_scraping\",\n",
    "                   query_fields=(\"headline\",\"body\")) -> None:\n",
    "    \"\"\"크롤링 후 JSONL, CSV 저장\"\"\"\n",
    "    slug = slugify(query)\n",
    "    base = pathlib.Path(out_dir)\n",
    "    base.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 모든 연도의 결과 수집\n",
    "    seen, rows = set(), []\n",
    "    for y, y_start, y_end in year_slices(start_date, end_date):\n",
    "        print(f\"  [{query}] Crawling {y}: {y_start} ~ {y_end}\")\n",
    "        for it in iter_results(query, y_start, y_end, query_fields=query_fields):\n",
    "            _id = it.get(\"id\")\n",
    "            if _id in seen:\n",
    "                continue\n",
    "            seen.add(_id)\n",
    "            rows.append(to_row(it))\n",
    "\n",
    "    # JSONL 저장\n",
    "    jsonl_path = base / f\"{slug}.jsonl\"\n",
    "    with jsonl_path.open(\"w\", encoding=\"utf-8\") as jf:\n",
    "        for r in rows:\n",
    "            jf.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"  [{query}] Total rows={len(rows)}  JSONL={jsonl_path.name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6603c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3: Batch Crawl & Summary =====\n",
    "\n",
    "def batch_crawl_and_summary(\n",
    "    people: List[str],\n",
    "    start_date: str = \"2017-01-01\",\n",
    "    end_date: str = \"2019-12-31\",\n",
    "    out_dir: str = \"guardian_scraping\",\n",
    "    query_fields=(\"headline\",\"body\"),\n",
    "    skip_existing: bool = True,\n",
    ") -> Dict[str, pathlib.Path]:\n",
    "    \"\"\"여러 인물에 대해 크롤링 후 summary CSV 생성\"\"\"\n",
    "    out_base = pathlib.Path(out_dir)\n",
    "    out_base.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for i, p in enumerate(people, 1):\n",
    "        slug = slugify(p)\n",
    "        jsonl_path = out_base / f\"{slug}.jsonl\"\n",
    "        \n",
    "        # 기존 파일 있으면 스킵\n",
    "        if skip_existing and jsonl_path.exists():\n",
    "            print(f\"\\n[{i}/{len(people)}] SKIP (exists): {p}\")\n",
    "        else:\n",
    "            print(f\"\\n[{i}/{len(people)}] Crawling: {p}\")\n",
    "            crawl_and_save(\n",
    "                query=p,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                out_dir=out_dir,\n",
    "                query_fields=query_fields,\n",
    "            )\n",
    "        \n",
    "        # 연도별 기사 수 집계\n",
    "        count_2017, count_2018, count_2019, total_count = 0, 0, 0, 0\n",
    "        if jsonl_path.exists():  # csv_path → jsonl_path로 변경\n",
    "            try:\n",
    "                # JSONL 파일에서 직접 읽기\n",
    "                rows = []\n",
    "                with jsonl_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                    for line in f:\n",
    "                        rows.append(json.loads(line))\n",
    "                \n",
    "                df = pd.DataFrame(rows)\n",
    "                total_count = len(df)\n",
    "                df['year'] = pd.to_datetime(df['webPublicationDate']).dt.year\n",
    "                count_2017 = len(df[df['year'] == 2017])\n",
    "                count_2018 = len(df[df['year'] == 2018])\n",
    "                count_2019 = len(df[df['year'] == 2019])\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Could not read {jsonl_path.name}: {e}\")\n",
    "        \n",
    "        summary_data.append({\n",
    "            \"person\": p,\n",
    "            \"slug\": slug,\n",
    "            \"2017\": count_2017,\n",
    "            \"2018\": count_2018,\n",
    "            \"2019\": count_2019,\n",
    "            \"total\": total_count,\n",
    "        })\n",
    "\n",
    "    # Summary CSV 저장\n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    summary_path = out_dir + \"/summary_counts.csv\"\n",
    "    df_summary.to_csv(summary_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"\\n\\nSaved summary: {summary_path}\")\n",
    "    print(f\"Total people crawled: {len(people)}\")\n",
    "    print(f\"Total articles: {df_summary['total'].sum()}\")\n",
    "    print(f\"  - 2017: {df_summary['2017'].sum()}\")\n",
    "    print(f\"  - 2018: {df_summary['2018'].sum()}\")\n",
    "    print(f\"  - 2019: {df_summary['2019'].sum()}\")\n",
    "\n",
    "    return {\"summary\": summary_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 299 names\n",
      "Unique: 288 people\n",
      "Duplicates: 11\n",
      "Duplicate names: ['Nancy Pelosi', 'Kim Jong Un', 'Jacinda Ardern', 'LeBron James', 'Jeff Bezos', 'Robert Mueller', 'Donald Trump', 'Pope Francis', 'Xi Jinping']\n",
      "\n",
      "Crawling list: ['Fatou Bensouda', 'Bob Bland', 'Savannah Guthrie', 'Ronan Farrow', 'Linda Sarsour', 'Ava DuVernay', 'Cyril Ramaphosa', 'Mohamed bin Zayed', 'Leila de Lima', 'Peggy Whitson', 'King Maha Vajiralongkorn', 'Indya Moore', 'Julian Assange', 'Conor McGregor', 'Constance Wu', 'Maxine Waters', 'George Church', 'Samantha Bee', 'Joanna Gaines', 'Chadwick Boseman', 'Christopher Wylie', 'Guillermo del Toro', 'Satya Nadella', 'Cindy Sherman', 'Chance the Rapper', 'Carl June', 'Mohammed bin Salman', 'Hamdi Ulukaya', 'Chip Gaines', 'Hoda Kotb', 'Ezra Levin', 'Zhang Kejian', 'Imran Khan', 'Grainne Griffin', 'Dwayne Johnson', 'Radhya Almutawakel', 'Ben Platt', 'Tamika Mallory', 'Elizabeth Warren', 'Kevin Durant', 'Ren Zhengfei', 'dream hampton', 'Desmond Meade', 'Barbara Rae-Venter', 'Jordan Peele', 'Donald Glover', 'Arundhati Katju', 'Matteo Salvini', 'Caster Semenya', 'Cameron Kasky', 'Moon Jae in', 'Thelma Aldana', 'Alex Wind', 'David Adjaye', 'Regina King', 'Hoesung Lee', 'Jeanne Gang', 'Greta Gerwig', 'Yuriko Koike', 'Mark Zuckerberg', 'Glenda Gray', 'Alessandro Michele', 'Jan Rader', 'Raf Simons', 'Nancy Pelosi', 'Trevor Noah', 'Nicole Kidman', 'Cindy Holland', 'Biram Dah Abeid', 'Jian Wei Pan', 'JJ Watt', 'Ann McKee', 'Kehinde Wiley', 'Loujain al Hathloul', 'Lady Gaga', 'John Legend', 'Margot Robbie', 'Lynn Nottage', 'Gavin Grimm', 'Hasan Minhaj', 'Samin Nosrat', 'Chloe Kim', 'Jeanette Vizguerra', 'Juan Guaido', 'Prince Harry', 'Colin Kaepernick', 'Mukesh Ambani', 'Sandra Day OConnor', 'Ruth Davidson', 'Margrethe Vestager', 'Tara Westover', 'Jennifer Lopez', 'Demi Lovato', 'Vijay Shekhar Sharma', 'General James Mattis', 'Zhang Yiming', 'Emmanuel Macron', 'Wang Qishan', 'Viola Davis', 'Maria Ressa', 'Sterling Brown', 'Roger Federer', 'Stephen Bannon', 'Daniel Ek', 'Alicia Keys', 'Arlette Contreras', 'Carmen Perez', 'Elon Musk', 'Giuliano Testa', 'Pony Ma', 'Colson Whitehead', 'Kim Jong Un', 'Scott Pruitt', 'Riz Ahmed', 'Ivanka Trump', 'Chuck Schumer', 'Greta Thunberg', 'Jerome Powell', 'Demis Hassabis', 'Michael Gillon', 'John Lewis', 'Bob Iger', 'Jared Kushner', 'Glenn Close', 'Jeff Sessions', 'Andres Manuel Lopez', 'Mohamed Salah', 'Neymar', 'Ryan Murphy', 'Janet Mock', 'Emma Stone', 'Jacinda Ardern', 'Virat Kohli', 'Reince Priebus', 'Barbara Lynch', 'Hugh Jackman', 'Cristina Jimenez', 'Marillyn Hewson', 'BTS', 'Celina Turchi', 'David Hogg', 'Sheikh Hasina', 'Daniela Vega', 'Ninja Blevins', 'James Corden', 'RuPaul', 'Tom Perez', 'Jay ONeal', 'Sandra Oh', 'Alex Morgan', 'Adam Rippon', 'Kumail Nanjiani', 'Sean Hannity', 'Vera Jourova', 'Bob Ferguson', 'Kirsten Green', 'Sarah Paulson', 'LeBron James', 'Millie Bobby Brown', 'Rihanna', 'Marlon James', 'Fred Swaniker', 'William Barr', 'Jeff Bezos', 'Jason Blum', 'Christine Blasey Ford', 'Mahershala Ali', 'Brie Larson', 'Ariana Grande', 'Ed Sheeran', 'Bhavish Aggarwal', 'Theo Epstein', 'Aileen Lee', 'Leah Greenberg', 'Evan Spiegel', 'Marica Branchesi', 'Adam Neumann', 'Sinta Nuriyah', 'Issa Rae', 'Narendra Modi', 'Tom Brady', 'Kevin Kwan', 'Rachael Denhollander', 'Spike Lee', 'Qasem Soleimani', 'Gayle King', 'Clare Waight Keller', 'Mitch McConnell', 'James Allison', 'Ashley Graham', 'Adam Bowen', 'JR artist', 'Meghan Markle', 'Tarana Burke', 'Janet Yellen', 'Jodi Kantor', 'Oprah Winfrey', 'Tiger Woods', 'Kesha', 'Jean Liu', 'Brett Kavanaugh', 'Ailbhe Smyth', 'Leslie Jones', 'Bernard Tyson', 'Gal Gadot', 'Justin Trudeau', 'Orla OConnor', 'Kenneth Frazier', 'Haider al Abadi', 'Robert Mueller', 'Jane Goodall', 'Mahathir Mohamad', 'Guus Velders', 'Cardi B', 'Massimo Bottura', 'Luchita Hurtado', 'Leana Wen', 'Chrissy Teigen', 'Lena Waithe', 'Emily Comer', 'Donald Trump', 'Leo Varadkar', 'Margaret Atwood', 'He Jiankui', 'Gretchen Carlson', 'Richard Madden', 'Benjamin Netanyahu', 'Michelle Obama', 'Mauricio Macri', 'Jose Andres', 'Pat McGrath', 'Rami Malek', 'Naomi Osaka', 'James Monsees', 'Ryan Reynolds', 'Sonia Friedman', 'Jair Bolsonaro', 'Roseanne Barr', 'Barry Jenkins', 'Natalie Batalha', 'Tiffany Haddish', 'Khalid', 'Jennifer Hyman', 'Judy Chicago', 'Alexandria Ocasio-Cortez', 'Nice Nailantei Lengete', 'Recep Tayyip Erdogan', 'Ryan Coogler', 'John Krasinski', 'Simone Biles', 'Taylor Swift', 'Emmerson Mnangagwa', 'Yalitza Aparicio', 'Shep Doeleman', 'Pope Francis', 'Deepika Padukone', 'Christian Siriano', 'Xi Jinping', 'Shawn Mendes', 'Fan Bingbing', 'Sadiq Khan', 'Jimmy Kimmel', 'Shinzo Abe', 'Elizabeth Diller', 'Mirian G', 'James Comey', 'Pierpaolo Piccioli', 'Theresa May', 'Masayoshi Son', 'Menaka Guruswamy', 'Jesmyn Ward', 'Carmen Yulin Cruz', 'Abiy Ahmed', 'Emilia Clarke', 'Emma Gonzalez', 'Rebekah Mercer', 'Raed Saleh', 'Rodrigo Duterte', 'Ozuna', 'Whitney Wolfe Herd', 'Kerry James Marshall', 'Guillem Anglada Escude', 'Vladimir Putin', 'Virgil Abloh', 'Juan Manuel Santos', 'Jaclyn Corin', 'David Hockney', 'Megan Twohey']\n",
      "\n",
      "\n",
      "[1/288] SKIP (exists): Fatou Bensouda\n",
      "\n",
      "[2/288] SKIP (exists): Bob Bland\n",
      "\n",
      "[3/288] SKIP (exists): Savannah Guthrie\n",
      "\n",
      "[4/288] SKIP (exists): Ronan Farrow\n",
      "\n",
      "[5/288] SKIP (exists): Linda Sarsour\n",
      "\n",
      "[6/288] SKIP (exists): Ava DuVernay\n",
      "\n",
      "[7/288] SKIP (exists): Cyril Ramaphosa\n",
      "\n",
      "[8/288] SKIP (exists): Mohamed bin Zayed\n",
      "\n",
      "[9/288] SKIP (exists): Leila de Lima\n",
      "\n",
      "[10/288] SKIP (exists): Peggy Whitson\n",
      "\n",
      "[11/288] SKIP (exists): King Maha Vajiralongkorn\n",
      "\n",
      "[12/288] SKIP (exists): Indya Moore\n",
      "\n",
      "[13/288] SKIP (exists): Julian Assange\n",
      "\n",
      "[14/288] SKIP (exists): Conor McGregor\n",
      "\n",
      "[15/288] SKIP (exists): Constance Wu\n",
      "\n",
      "[16/288] SKIP (exists): Maxine Waters\n",
      "\n",
      "[17/288] SKIP (exists): George Church\n",
      "\n",
      "[18/288] SKIP (exists): Samantha Bee\n",
      "\n",
      "[19/288] SKIP (exists): Joanna Gaines\n",
      "\n",
      "[20/288] SKIP (exists): Chadwick Boseman\n",
      "\n",
      "[21/288] SKIP (exists): Christopher Wylie\n",
      "\n",
      "[22/288] SKIP (exists): Guillermo del Toro\n",
      "\n",
      "[23/288] SKIP (exists): Satya Nadella\n",
      "\n",
      "[24/288] SKIP (exists): Cindy Sherman\n",
      "\n",
      "[25/288] SKIP (exists): Chance the Rapper\n",
      "\n",
      "[26/288] SKIP (exists): Carl June\n",
      "\n",
      "[27/288] SKIP (exists): Mohammed bin Salman\n",
      "\n",
      "[28/288] SKIP (exists): Hamdi Ulukaya\n",
      "\n",
      "[29/288] SKIP (exists): Chip Gaines\n",
      "\n",
      "[30/288] SKIP (exists): Hoda Kotb\n",
      "\n",
      "[31/288] SKIP (exists): Ezra Levin\n",
      "\n",
      "[32/288] SKIP (exists): Zhang Kejian\n",
      "\n",
      "[33/288] SKIP (exists): Imran Khan\n",
      "\n",
      "[34/288] SKIP (exists): Grainne Griffin\n",
      "\n",
      "[35/288] SKIP (exists): Dwayne Johnson\n",
      "\n",
      "[36/288] SKIP (exists): Radhya Almutawakel\n",
      "\n",
      "[37/288] SKIP (exists): Ben Platt\n",
      "\n",
      "[38/288] SKIP (exists): Tamika Mallory\n",
      "\n",
      "[39/288] SKIP (exists): Elizabeth Warren\n",
      "\n",
      "[40/288] SKIP (exists): Kevin Durant\n",
      "\n",
      "[41/288] SKIP (exists): Ren Zhengfei\n",
      "\n",
      "[42/288] SKIP (exists): dream hampton\n",
      "\n",
      "[43/288] SKIP (exists): Desmond Meade\n",
      "\n",
      "[44/288] SKIP (exists): Barbara Rae-Venter\n",
      "\n",
      "[45/288] SKIP (exists): Jordan Peele\n",
      "\n",
      "[46/288] SKIP (exists): Donald Glover\n",
      "\n",
      "[47/288] SKIP (exists): Arundhati Katju\n",
      "\n",
      "[48/288] SKIP (exists): Matteo Salvini\n",
      "\n",
      "[49/288] SKIP (exists): Caster Semenya\n",
      "\n",
      "[50/288] SKIP (exists): Cameron Kasky\n",
      "\n",
      "[51/288] SKIP (exists): Moon Jae in\n",
      "\n",
      "[52/288] SKIP (exists): Thelma Aldana\n",
      "\n",
      "[53/288] SKIP (exists): Alex Wind\n",
      "\n",
      "[54/288] SKIP (exists): David Adjaye\n",
      "\n",
      "[55/288] SKIP (exists): Regina King\n",
      "\n",
      "[56/288] SKIP (exists): Hoesung Lee\n",
      "\n",
      "[57/288] SKIP (exists): Jeanne Gang\n",
      "\n",
      "[58/288] SKIP (exists): Greta Gerwig\n",
      "\n",
      "[59/288] SKIP (exists): Yuriko Koike\n",
      "\n",
      "[60/288] SKIP (exists): Mark Zuckerberg\n",
      "\n",
      "[61/288] SKIP (exists): Glenda Gray\n",
      "\n",
      "[62/288] SKIP (exists): Alessandro Michele\n",
      "\n",
      "[63/288] SKIP (exists): Jan Rader\n",
      "\n",
      "[64/288] SKIP (exists): Raf Simons\n",
      "\n",
      "[65/288] SKIP (exists): Nancy Pelosi\n",
      "\n",
      "[66/288] SKIP (exists): Trevor Noah\n",
      "\n",
      "[67/288] SKIP (exists): Nicole Kidman\n",
      "\n",
      "[68/288] SKIP (exists): Cindy Holland\n",
      "\n",
      "[69/288] SKIP (exists): Biram Dah Abeid\n",
      "\n",
      "[70/288] SKIP (exists): Jian Wei Pan\n",
      "\n",
      "[71/288] SKIP (exists): JJ Watt\n",
      "\n",
      "[72/288] SKIP (exists): Ann McKee\n",
      "\n",
      "[73/288] SKIP (exists): Kehinde Wiley\n",
      "\n",
      "[74/288] SKIP (exists): Loujain al Hathloul\n",
      "\n",
      "[75/288] SKIP (exists): Lady Gaga\n",
      "\n",
      "[76/288] SKIP (exists): John Legend\n",
      "\n",
      "[77/288] SKIP (exists): Margot Robbie\n",
      "\n",
      "[78/288] SKIP (exists): Lynn Nottage\n",
      "\n",
      "[79/288] SKIP (exists): Gavin Grimm\n",
      "\n",
      "[80/288] SKIP (exists): Hasan Minhaj\n",
      "\n",
      "[81/288] SKIP (exists): Samin Nosrat\n",
      "\n",
      "[82/288] SKIP (exists): Chloe Kim\n",
      "\n",
      "[83/288] SKIP (exists): Jeanette Vizguerra\n",
      "\n",
      "[84/288] SKIP (exists): Juan Guaido\n",
      "\n",
      "[85/288] SKIP (exists): Prince Harry\n",
      "\n",
      "[86/288] SKIP (exists): Colin Kaepernick\n",
      "\n",
      "[87/288] SKIP (exists): Mukesh Ambani\n",
      "\n",
      "[88/288] SKIP (exists): Sandra Day OConnor\n",
      "\n",
      "[89/288] SKIP (exists): Ruth Davidson\n",
      "\n",
      "[90/288] SKIP (exists): Margrethe Vestager\n",
      "\n",
      "[91/288] SKIP (exists): Tara Westover\n",
      "\n",
      "[92/288] SKIP (exists): Jennifer Lopez\n",
      "\n",
      "[93/288] SKIP (exists): Demi Lovato\n",
      "\n",
      "[94/288] SKIP (exists): Vijay Shekhar Sharma\n",
      "\n",
      "[95/288] SKIP (exists): General James Mattis\n",
      "\n",
      "[96/288] SKIP (exists): Zhang Yiming\n",
      "\n",
      "[97/288] SKIP (exists): Emmanuel Macron\n",
      "\n",
      "[98/288] SKIP (exists): Wang Qishan\n",
      "\n",
      "[99/288] SKIP (exists): Viola Davis\n",
      "\n",
      "[100/288] SKIP (exists): Maria Ressa\n",
      "\n",
      "[101/288] SKIP (exists): Sterling Brown\n",
      "\n",
      "[102/288] SKIP (exists): Roger Federer\n",
      "\n",
      "[103/288] SKIP (exists): Stephen Bannon\n",
      "\n",
      "[104/288] SKIP (exists): Daniel Ek\n",
      "\n",
      "[105/288] SKIP (exists): Alicia Keys\n",
      "\n",
      "[106/288] SKIP (exists): Arlette Contreras\n",
      "\n",
      "[107/288] SKIP (exists): Carmen Perez\n",
      "\n",
      "[108/288] SKIP (exists): Elon Musk\n",
      "\n",
      "[109/288] SKIP (exists): Giuliano Testa\n",
      "\n",
      "[110/288] SKIP (exists): Pony Ma\n",
      "\n",
      "[111/288] SKIP (exists): Colson Whitehead\n",
      "\n",
      "[112/288] SKIP (exists): Kim Jong Un\n",
      "\n",
      "[113/288] SKIP (exists): Scott Pruitt\n",
      "\n",
      "[114/288] SKIP (exists): Riz Ahmed\n",
      "\n",
      "[115/288] SKIP (exists): Ivanka Trump\n",
      "\n",
      "[116/288] SKIP (exists): Chuck Schumer\n",
      "\n",
      "[117/288] SKIP (exists): Greta Thunberg\n",
      "\n",
      "[118/288] SKIP (exists): Jerome Powell\n",
      "\n",
      "[119/288] SKIP (exists): Demis Hassabis\n",
      "\n",
      "[120/288] SKIP (exists): Michael Gillon\n",
      "\n",
      "[121/288] SKIP (exists): John Lewis\n",
      "\n",
      "[122/288] SKIP (exists): Bob Iger\n",
      "\n",
      "[123/288] SKIP (exists): Jared Kushner\n",
      "\n",
      "[124/288] SKIP (exists): Glenn Close\n",
      "\n",
      "[125/288] SKIP (exists): Jeff Sessions\n",
      "\n",
      "[126/288] SKIP (exists): Andres Manuel Lopez\n",
      "\n",
      "[127/288] SKIP (exists): Mohamed Salah\n",
      "\n",
      "[128/288] SKIP (exists): Neymar\n",
      "\n",
      "[129/288] SKIP (exists): Ryan Murphy\n",
      "\n",
      "[130/288] SKIP (exists): Janet Mock\n",
      "\n",
      "[131/288] SKIP (exists): Emma Stone\n",
      "\n",
      "[132/288] SKIP (exists): Jacinda Ardern\n",
      "\n",
      "[133/288] SKIP (exists): Virat Kohli\n",
      "\n",
      "[134/288] SKIP (exists): Reince Priebus\n",
      "\n",
      "[135/288] SKIP (exists): Barbara Lynch\n",
      "\n",
      "[136/288] SKIP (exists): Hugh Jackman\n",
      "\n",
      "[137/288] SKIP (exists): Cristina Jimenez\n",
      "\n",
      "[138/288] SKIP (exists): Marillyn Hewson\n",
      "\n",
      "[139/288] SKIP (exists): BTS\n",
      "\n",
      "[140/288] SKIP (exists): Celina Turchi\n",
      "\n",
      "[141/288] SKIP (exists): David Hogg\n",
      "\n",
      "[142/288] SKIP (exists): Sheikh Hasina\n",
      "\n",
      "[143/288] SKIP (exists): Daniela Vega\n",
      "\n",
      "[144/288] SKIP (exists): Ninja Blevins\n",
      "\n",
      "[145/288] SKIP (exists): James Corden\n",
      "\n",
      "[146/288] SKIP (exists): RuPaul\n",
      "\n",
      "[147/288] SKIP (exists): Tom Perez\n",
      "\n",
      "[148/288] SKIP (exists): Jay ONeal\n",
      "\n",
      "[149/288] SKIP (exists): Sandra Oh\n",
      "\n",
      "[150/288] SKIP (exists): Alex Morgan\n",
      "\n",
      "[151/288] SKIP (exists): Adam Rippon\n",
      "\n",
      "[152/288] SKIP (exists): Kumail Nanjiani\n",
      "\n",
      "[153/288] Crawling: Sean Hannity\n",
      "  [Sean Hannity] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Sean Hannity] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Sean Hannity] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Sean Hannity] Total rows=5332  JSONL=sean_hannity.jsonl\n",
      "\n",
      "[154/288] Crawling: Vera Jourova\n",
      "  [Vera Jourova] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Vera Jourova] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Vera Jourova] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Vera Jourova] Total rows=621  JSONL=vera_jourova.jsonl\n",
      "\n",
      "[155/288] Crawling: Bob Ferguson\n",
      "  [Bob Ferguson] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Bob Ferguson] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Bob Ferguson] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Bob Ferguson] Total rows=3924  JSONL=bob_ferguson.jsonl\n",
      "\n",
      "[156/288] Crawling: Kirsten Green\n",
      "  [Kirsten Green] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Kirsten Green] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Kirsten Green] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Kirsten Green] Total rows=1571  JSONL=kirsten_green.jsonl\n",
      "\n",
      "[157/288] SKIP (exists): Sarah Paulson\n",
      "\n",
      "[158/288] Crawling: LeBron James\n",
      "  [LeBron James] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [LeBron James] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [LeBron James] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [LeBron James] Total rows=1287  JSONL=lebron_james.jsonl\n",
      "\n",
      "[159/288] SKIP (exists): Millie Bobby Brown\n",
      "\n",
      "[160/288] SKIP (exists): Rihanna\n",
      "\n",
      "[161/288] SKIP (exists): Marlon James\n",
      "\n",
      "[162/288] Crawling: Fred Swaniker\n",
      "  [Fred Swaniker] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Fred Swaniker] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Fred Swaniker] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Fred Swaniker] Total rows=1908  JSONL=fred_swaniker.jsonl\n",
      "\n",
      "[163/288] Crawling: William Barr\n",
      "  [William Barr] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [William Barr] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [William Barr] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [William Barr] Total rows=1128  JSONL=william_barr.jsonl\n",
      "\n",
      "[164/288] SKIP (exists): Jeff Bezos\n",
      "\n",
      "[165/288] SKIP (exists): Jason Blum\n",
      "\n",
      "[166/288] Crawling: Christine Blasey Ford\n",
      "  [Christine Blasey Ford] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Christine Blasey Ford] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Christine Blasey Ford] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Christine Blasey Ford] Total rows=5057  JSONL=christine_blasey_ford.jsonl\n",
      "\n",
      "[167/288] SKIP (exists): Mahershala Ali\n",
      "\n",
      "[168/288] Crawling: Brie Larson\n",
      "  [Brie Larson] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Brie Larson] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Brie Larson] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Brie Larson] Total rows=376  JSONL=brie_larson.jsonl\n",
      "\n",
      "[169/288] SKIP (exists): Ariana Grande\n",
      "\n",
      "[170/288] Crawling: Ed Sheeran\n",
      "  [Ed Sheeran] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Ed Sheeran] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Ed Sheeran] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Ed Sheeran] Total rows=917  JSONL=ed_sheeran.jsonl\n",
      "\n",
      "[171/288] Crawling: Bhavish Aggarwal\n",
      "  [Bhavish Aggarwal] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Bhavish Aggarwal] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Bhavish Aggarwal] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Bhavish Aggarwal] Total rows=13  JSONL=bhavish_aggarwal.jsonl\n",
      "\n",
      "[172/288] Crawling: Theo Epstein\n",
      "  [Theo Epstein] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Theo Epstein] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Theo Epstein] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Theo Epstein] Total rows=1311  JSONL=theo_epstein.jsonl\n",
      "\n",
      "[173/288] Crawling: Aileen Lee\n",
      "  [Aileen Lee] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Aileen Lee] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Aileen Lee] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Aileen Lee] Total rows=301  JSONL=aileen_lee.jsonl\n",
      "\n",
      "[174/288] Crawling: Leah Greenberg\n",
      "  [Leah Greenberg] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Leah Greenberg] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Leah Greenberg] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Leah Greenberg] Total rows=684  JSONL=leah_greenberg.jsonl\n",
      "\n",
      "[175/288] SKIP (exists): Evan Spiegel\n",
      "\n",
      "[176/288] Crawling: Marica Branchesi\n",
      "  [Marica Branchesi] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Marica Branchesi] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Marica Branchesi] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Marica Branchesi] Total rows=1  JSONL=marica_branchesi.jsonl\n",
      "\n",
      "[177/288] SKIP (exists): Adam Neumann\n",
      "\n",
      "[178/288] SKIP (exists): Sinta Nuriyah\n",
      "\n",
      "[179/288] Crawling: Issa Rae\n",
      "  [Issa Rae] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Issa Rae] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Issa Rae] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Issa Rae] Total rows=677  JSONL=issa_rae.jsonl\n",
      "\n",
      "[180/288] SKIP (exists): Narendra Modi\n",
      "\n",
      "[181/288] Crawling: Tom Brady\n",
      "  [Tom Brady] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Tom Brady] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Tom Brady] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Tom Brady] Total rows=2028  JSONL=tom_brady.jsonl\n",
      "\n",
      "[182/288] SKIP (exists): Kevin Kwan\n",
      "\n",
      "[183/288] Crawling: Rachael Denhollander\n",
      "  [Rachael Denhollander] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Rachael Denhollander] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Rachael Denhollander] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Rachael Denhollander] Total rows=583  JSONL=rachael_denhollander.jsonl\n",
      "\n",
      "[184/288] SKIP (exists): Spike Lee\n",
      "\n",
      "[185/288] SKIP (exists): Qasem Soleimani\n",
      "\n",
      "[186/288] SKIP (exists): Gayle King\n",
      "\n",
      "[187/288] Crawling: Clare Waight Keller\n",
      "  [Clare Waight Keller] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Clare Waight Keller] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Clare Waight Keller] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Clare Waight Keller] Total rows=1751  JSONL=clare_waight_keller.jsonl\n",
      "\n",
      "[188/288] SKIP (exists): Mitch McConnell\n",
      "\n",
      "[189/288] SKIP (exists): James Allison\n",
      "\n",
      "[190/288] Crawling: Ashley Graham\n",
      "  [Ashley Graham] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Ashley Graham] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Ashley Graham] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Ashley Graham] Total rows=5074  JSONL=ashley_graham.jsonl\n",
      "\n",
      "[191/288] SKIP (exists): Adam Bowen\n",
      "\n",
      "[192/288] Crawling: JR artist\n",
      "  [JR artist] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [JR artist] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [JR artist] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [JR artist] Total rows=3592  JSONL=jr_artist.jsonl\n",
      "\n",
      "[193/288] Crawling: Meghan Markle\n",
      "  [Meghan Markle] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Meghan Markle] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Meghan Markle] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Meghan Markle] Total rows=1117  JSONL=meghan_markle.jsonl\n",
      "\n",
      "[194/288] Crawling: Tarana Burke\n",
      "  [Tarana Burke] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Tarana Burke] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Tarana Burke] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Tarana Burke] Total rows=1498  JSONL=tarana_burke.jsonl\n",
      "\n",
      "[195/288] Crawling: Janet Yellen\n",
      "  [Janet Yellen] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Janet Yellen] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Janet Yellen] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Janet Yellen] Total rows=1453  JSONL=janet_yellen.jsonl\n",
      "\n",
      "[196/288] SKIP (exists): Jodi Kantor\n",
      "\n",
      "[197/288] SKIP (exists): Oprah Winfrey\n",
      "\n",
      "[198/288] SKIP (exists): Tiger Woods\n",
      "\n",
      "[199/288] SKIP (exists): Kesha\n",
      "\n",
      "[200/288] Crawling: Jean Liu\n",
      "  [Jean Liu] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Jean Liu] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Jean Liu] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Jean Liu] Total rows=6101  JSONL=jean_liu.jsonl\n",
      "\n",
      "[201/288] Crawling: Brett Kavanaugh\n",
      "  [Brett Kavanaugh] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Brett Kavanaugh] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Brett Kavanaugh] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Brett Kavanaugh] Total rows=1882  JSONL=brett_kavanaugh.jsonl\n",
      "\n",
      "[202/288] Crawling: Ailbhe Smyth\n",
      "  [Ailbhe Smyth] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Ailbhe Smyth] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Ailbhe Smyth] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Ailbhe Smyth] Total rows=756  JSONL=ailbhe_smyth.jsonl\n",
      "\n",
      "[203/288] Crawling: Leslie Jones\n",
      "  [Leslie Jones] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Leslie Jones] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Leslie Jones] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Leslie Jones] Total rows=1909  JSONL=leslie_jones.jsonl\n",
      "\n",
      "[204/288] Crawling: Bernard Tyson\n",
      "  [Bernard Tyson] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Bernard Tyson] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Bernard Tyson] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Bernard Tyson] Total rows=2715  JSONL=bernard_tyson.jsonl\n",
      "\n",
      "[205/288] Crawling: Gal Gadot\n",
      "  [Gal Gadot] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Gal Gadot] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Gal Gadot] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Gal Gadot] Total rows=376  JSONL=gal_gadot.jsonl\n",
      "\n",
      "[206/288] Crawling: Justin Trudeau\n",
      "  [Justin Trudeau] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Justin Trudeau] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Justin Trudeau] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Justin Trudeau] Total rows=4983  JSONL=justin_trudeau.jsonl\n",
      "\n",
      "[207/288] Crawling: Orla OConnor\n",
      "  [Orla OConnor] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Orla OConnor] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Orla OConnor] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Orla OConnor] Total rows=197  JSONL=orla_oconnor.jsonl\n",
      "\n",
      "[208/288] SKIP (exists): Kenneth Frazier\n",
      "\n",
      "[209/288] Crawling: Haider al Abadi\n",
      "  [Haider al Abadi] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Haider al Abadi] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Haider al Abadi] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Haider al Abadi] Total rows=423  JSONL=haider_al_abadi.jsonl\n",
      "\n",
      "[210/288] Crawling: Robert Mueller\n",
      "  [Robert Mueller] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Robert Mueller] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Robert Mueller] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Robert Mueller] Total rows=2975  JSONL=robert_mueller.jsonl\n",
      "\n",
      "[211/288] SKIP (exists): Jane Goodall\n",
      "\n",
      "[212/288] Crawling: Mahathir Mohamad\n",
      "  [Mahathir Mohamad] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Mahathir Mohamad] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Mahathir Mohamad] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Mahathir Mohamad] Total rows=166  JSONL=mahathir_mohamad.jsonl\n",
      "\n",
      "[213/288] Crawling: Guus Velders\n",
      "  [Guus Velders] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Guus Velders] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Guus Velders] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Guus Velders] Total rows=83  JSONL=guus_velders.jsonl\n",
      "\n",
      "[214/288] Crawling: Cardi B\n",
      "  [Cardi B] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Cardi B] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Cardi B] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Cardi B] Total rows=526  JSONL=cardi_b.jsonl\n",
      "\n",
      "[215/288] Crawling: Massimo Bottura\n",
      "  [Massimo Bottura] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Massimo Bottura] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Massimo Bottura] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Massimo Bottura] Total rows=312  JSONL=massimo_bottura.jsonl\n",
      "\n",
      "[216/288] Crawling: Luchita Hurtado\n",
      "  [Luchita Hurtado] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Luchita Hurtado] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Luchita Hurtado] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Luchita Hurtado] Total rows=28  JSONL=luchita_hurtado.jsonl\n",
      "\n",
      "[217/288] Crawling: Leana Wen\n",
      "  [Leana Wen] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Leana Wen] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Leana Wen] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Leana Wen] Total rows=177  JSONL=leana_wen.jsonl\n",
      "\n",
      "[218/288] Crawling: Chrissy Teigen\n",
      "  [Chrissy Teigen] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Chrissy Teigen] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Chrissy Teigen] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Chrissy Teigen] Total rows=182  JSONL=chrissy_teigen.jsonl\n",
      "\n",
      "[219/288] SKIP (exists): Lena Waithe\n",
      "\n",
      "[220/288] Crawling: Emily Comer\n",
      "  [Emily Comer] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Emily Comer] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Emily Comer] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Emily Comer] Total rows=3693  JSONL=emily_comer.jsonl\n",
      "\n",
      "[221/288] SKIP (exists): Donald Trump\n",
      "\n",
      "[222/288] SKIP (exists): Leo Varadkar\n",
      "\n",
      "[223/288] SKIP (exists): Margaret Atwood\n",
      "\n",
      "[224/288] Crawling: He Jiankui\n",
      "  [He Jiankui] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [He Jiankui] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [He Jiankui] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [He Jiankui] Total rows=2509  JSONL=he_jiankui.jsonl\n",
      "\n",
      "[225/288] Crawling: Gretchen Carlson\n",
      "  [Gretchen Carlson] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Gretchen Carlson] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Gretchen Carlson] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Gretchen Carlson] Total rows=424  JSONL=gretchen_carlson.jsonl\n",
      "\n",
      "[226/288] Crawling: Richard Madden\n",
      "  [Richard Madden] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Richard Madden] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Richard Madden] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Richard Madden] Total rows=987  JSONL=richard_madden.jsonl\n",
      "\n",
      "[227/288] SKIP (exists): Benjamin Netanyahu\n",
      "\n",
      "[228/288] Crawling: Michelle Obama\n",
      "  [Michelle Obama] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Michelle Obama] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Michelle Obama] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Michelle Obama] Total rows=3271  JSONL=michelle_obama.jsonl\n",
      "\n",
      "[229/288] Crawling: Mauricio Macri\n",
      "  [Mauricio Macri] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Mauricio Macri] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Mauricio Macri] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Mauricio Macri] Total rows=2261  JSONL=mauricio_macri.jsonl\n",
      "\n",
      "[230/288] SKIP (exists): Jose Andres\n",
      "\n",
      "[231/288] SKIP (exists): Pat McGrath\n",
      "\n",
      "[232/288] SKIP (exists): Rami Malek\n",
      "\n",
      "[233/288] Crawling: Naomi Osaka\n",
      "  [Naomi Osaka] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Naomi Osaka] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Naomi Osaka] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Naomi Osaka] Total rows=1802  JSONL=naomi_osaka.jsonl\n",
      "\n",
      "[234/288] SKIP (exists): James Monsees\n",
      "\n",
      "[235/288] Crawling: Ryan Reynolds\n",
      "  [Ryan Reynolds] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Ryan Reynolds] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Ryan Reynolds] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Ryan Reynolds] Total rows=8467  JSONL=ryan_reynolds.jsonl\n",
      "\n",
      "[236/288] Crawling: Sonia Friedman\n",
      "  [Sonia Friedman] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Sonia Friedman] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Sonia Friedman] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Sonia Friedman] Total rows=995  JSONL=sonia_friedman.jsonl\n",
      "\n",
      "[237/288] SKIP (exists): Jair Bolsonaro\n",
      "\n",
      "[238/288] Crawling: Roseanne Barr\n",
      "  [Roseanne Barr] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Roseanne Barr] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Roseanne Barr] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Roseanne Barr] Total rows=983  JSONL=roseanne_barr.jsonl\n",
      "\n",
      "[239/288] SKIP (exists): Barry Jenkins\n",
      "\n",
      "[240/288] Crawling: Natalie Batalha\n",
      "  [Natalie Batalha] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Natalie Batalha] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Natalie Batalha] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Natalie Batalha] Total rows=1510  JSONL=natalie_batalha.jsonl\n",
      "\n",
      "[241/288] SKIP (exists): Tiffany Haddish\n",
      "\n",
      "[242/288] Crawling: Khalid\n",
      "  [Khalid] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Khalid] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Khalid] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Khalid] Total rows=559  JSONL=khalid.jsonl\n",
      "\n",
      "[243/288] Crawling: Jennifer Hyman\n",
      "  [Jennifer Hyman] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Jennifer Hyman] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Jennifer Hyman] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Jennifer Hyman] Total rows=3198  JSONL=jennifer_hyman.jsonl\n",
      "\n",
      "[244/288] SKIP (exists): Judy Chicago\n",
      "\n",
      "[245/288] Crawling: Alexandria Ocasio-Cortez\n",
      "  [Alexandria Ocasio-Cortez] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Alexandria Ocasio-Cortez] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Alexandria Ocasio-Cortez] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Alexandria Ocasio-Cortez] Total rows=1427  JSONL=alexandria_ocasio_cortez.jsonl\n",
      "\n",
      "[246/288] Crawling: Nice Nailantei Lengete\n",
      "  [Nice Nailantei Lengete] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Nice Nailantei Lengete] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Nice Nailantei Lengete] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Nice Nailantei Lengete] Total rows=145  JSONL=nice_nailantei_lengete.jsonl\n",
      "\n",
      "[247/288] Crawling: Recep Tayyip Erdogan\n",
      "  [Recep Tayyip Erdogan] Crawling 2017: 2017-01-01 ~ 2017-12-31\n",
      "  [Recep Tayyip Erdogan] Crawling 2018: 2018-01-01 ~ 2018-12-31\n",
      "  [Recep Tayyip Erdogan] Crawling 2019: 2019-01-01 ~ 2019-12-31\n",
      "  [Recep Tayyip Erdogan] Total rows=1246  JSONL=recep_tayyip_erdogan.jsonl\n",
      "\n",
      "[248/288] Crawling: Ryan Coogler\n",
      "  [Ryan Coogler] Crawling 2017: 2017-01-01 ~ 2017-12-31\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 4: Run =====\n",
    "\n",
    "# people_list.txt 파일 읽기\n",
    "with open('people_list.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "people_list = content.split('\\n')\n",
    "people_list = [name.strip() for name in people_list if name.strip()]\n",
    "\n",
    "# 중복 체크\n",
    "duplicates = [name for name in set(people_list) if people_list.count(name) > 1]\n",
    "people = list(set(people_list))\n",
    "\n",
    "print(f\"Total: {len(people_list)} names\")\n",
    "print(f\"Unique: {len(people)} people\")\n",
    "print(f\"Duplicates: {len(people_list) - len(people)}\")\n",
    "if duplicates:\n",
    "    print(f\"Duplicate names: {duplicates}\")\n",
    "print(f\"\\nCrawling list: {people}\")\n",
    "print()\n",
    "\n",
    "#people = [\"Samantha Bee\",\"Constance Wu\"]\n",
    "# 크롤링 실행\n",
    "paths = batch_crawl_and_summary(\n",
    "    people=people,\n",
    "    start_date=\"2017-01-01\",\n",
    "    end_date=\"2019-12-31\",\n",
    "    out_dir=\"guardian_raw_scraping\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58518828",
   "metadata": {},
   "source": [
    "# Only top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e145a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 people by total articles: 2\n",
      "Total articles: 2920\n",
      "\n",
      "Top 10:\n",
      "      person  total\n",
      "Samantha Bee   2267\n",
      "Constance Wu    653\n",
      "\n",
      "Saved: people_top100_list.txt\n",
      "\n",
      "Copied 2 jsonl files to guardian_top100_scraping/\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 5: Extract Top 100 & Copy Files =====\n",
    "\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# summary_counts.csv 읽기\n",
    "df = pd.read_csv('guardian_raw_scraping/summary_counts.csv')\n",
    "\n",
    "# total 기준 내림차순 정렬 후 top 100 추출\n",
    "df_sorted = df.sort_values('total', ascending=False).head(100)\n",
    "top100_people = df_sorted['person'].tolist()\n",
    "\n",
    "print(f\"Top 100 people by total articles: {len(top100_people)}\")\n",
    "print(f\"Total articles: {df_sorted['total'].sum()}\")\n",
    "print(f\"\\nTop 10:\")\n",
    "print(df_sorted[['person', 'total']].head(10).to_string(index=False))\n",
    "\n",
    "# people_top100_list.txt 저장\n",
    "with open('people_top100_list.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(top100_people))\n",
    "print(f\"\\nSaved: people_top100_list.txt\")\n",
    "\n",
    "# guardian_top100_scraping 폴더 생성\n",
    "new_dir = 'guardian_top100_scraping'\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "# jsonl 파일 복사\n",
    "copied_count = 0\n",
    "for person in top100_people:\n",
    "    slug = df_sorted[df_sorted['person'] == person]['slug'].values[0]\n",
    "    src_file = f'guardian_raw_scraping/{slug}.jsonl'\n",
    "    dst_file = f'{new_dir}/{slug}.jsonl'\n",
    "    \n",
    "    if os.path.exists(src_file):\n",
    "        shutil.copy2(src_file, dst_file)\n",
    "        copied_count += 1\n",
    "\n",
    "print(f\"\\nCopied {copied_count} jsonl files to {new_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
